### 불용어(stopword)

- **불용어(stopword)**

    - 자주 출현하지만 그 의미는 중요치 않은 단어들을 의미함
 
    - ex: 관사(a, an, the)나 접속사(and, or)
 
    - 어떤 토큰들을 불용어로 처리하여 제외할지는 상황에 따라 다름
    
    - 단, NLTK 등의 라이브러리에서 일반적으로 쓰는 불용어 리스트는 존재
 
        - 라이브러리마다 불용어 리스트가 다를 수 있음  
 
    - 전통적인 NLP에서는 불용어 제거가 필수적, 하지만 딥러닝 기반 NLP에서는 그 중요성이 예전보다는 감소함 (스스로 처리하기 때문)
  
<br/>

- scikit-learn과 NLTK 불용어의 합집합 및 교집합 관련 예시

```ruby
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words
from nltk.corpus import stopwords

len(sklearn_stop_words) # scikit-learn이 제공하는 불용어 개수
### 출력 : 318

len(stopwords.words('english')) # NLTK에서 제공하는 영어 불용어 개수를 세어줌 
### 출력 : 179

len(stop_words.union(sklearn_stop_words)) # NLTK와 scikit-learn 불용어를 합쳐서 중복 없이 모은 총 개수를 계산
### 출력 : 378

len(stop_words.intersection(sklearn_stop_words)) # 두 라이브러리 불용어 목록에서 공통으로 들어 있는 단어 개수를 계산
### 출력 : 119
```

<br/>

### 정규화(normalization)

- **정규화(normalization)** : 실질적으로는 의미가 같으나 표현 방법이 다른 단어들을 통합하는 과정

    - 대소문자 통합
 
        - 장점 : 약 절반 정도 토큰 수를 줄일 수 있음
     
            -  기계학습 모델의 과적합을 줄여줌
         
            -  검색에 활용될 경우 검색 엔진의 재현율(recall) 개선에 기여할 수 있음
         
            -  만약 통합되지 않으면 Age와 age가 다른 단어로 인식
     
        - 단점 : 대문자로 인해 지명, 상표 등 고유명사를 인식이 어려움 -> 성능 저하
     
            - 의도적으로 쓰인 대문자를 구분, 문장의 시작을 소문자로 적용하는 방법이 존재
         
                - 하지만, 이 경우 "Tom is here."처럼 사람 이름으로 시작할 경우 문제 발생
             
                - **즉, 상황에 따라 깊이 생각해보고 적용할 필요가 있음**
    
    - 어간 추출
 
        - 어간 : 복수형(-s), 진행형(-ing) 등을 떼어난 근본 단어 
    
    - 표제어 추출
 
        - 표제어 : 기본형

<br/>

### 재현율(recall) & 정밀도(precision)

- 검색 성능을 평가할 때 쓰는 두 가지 지표

    - **재현율(recall)**: 실제로 관련 있는 문서 중에서 얼마나 많이 찾아냈는가?

    - **정밀도(precision)**: 찾아낸 문서 중에서 실제로 관련 있는 문서가 얼마나 되는가?

<br/>

- 일반적으로 어휘 정규화는 검색의 **재현율을 높이지만 정밀도를 낮추게 됨**

    - 정규화를 하면 많은 문서를 찾을 수 있지만, 그중에는 원하지 않는 결과도 섞일 가능성이 커짐 
    
    - ex: "Apple" (회사 Apple을 찾고 싶음) -> 정규화로 "apple"로 변환 -> **정밀도 저하**
    
    - 이에 검색 엔진에서 정규화를 회피하는 수단으로 “” 기능을 제공
     
       - "" : 정규화 없이 그대로 검색할 수 있게 기능

<br/>

### 어간 추출(stemming) 기법

- **어간 추출(stemming) 기법**

    - 추출된 어간은 반드시 사전에 나오는 형태여야 할 필요는 없고, 한 어간의 다양한 형태를 대표할 수 있으면 됨
 
    - ex: study, studies, studying, studied 를 studi로 추출을 하여 하나로 묶어도 괜찮음
 
       - 어간 추출은 완벽한 단어가 목표가 아니라 하나로 **같은 뿌리를 공유하는 단어를 하나로 묶는게 핵심**

<br/>

- 어간 추출 또한 정규화의 일종이므로 **재현율을 높이지만 정밀도는 감소**

    - ex:  “Dr. House’s call” 라는 미국 드라마 제목을 어간추출 해주면 “dr house call”
 
        - 결과적으로 드라마가 아니라 “의사 집에 전화하다” 같은 엉뚱한 의미로 검색될 수 있음 

<br/>

### 간단한 어간 추출 예시 

- 규칙
 
    - 단어가 둘 이상의 s로 끝나면, 어간은 그 단어 자체이며 별도의 접미사 없음
    
    - 단어가 하나의 s로 끝나면 어간은 s를 제외한 부분이며, s가 접미사가 됨
   
    - 단어가 s로 끝나지 않으면 어간은 그 단어 자체이고 별도의 접미사가 없음


```ruby
>>> def stem(phrase):  
...     # phrase(문자열)을 입력으로 받아서 어간을 추출하는 함수 정의
...     
...     return ' '.join(   # 처리된 단어들을 공백으로 연결하여 반환
...         [re.findall('^(.*ss|.*?)(s)?$',  # 정규표현식으로 단어 끝의 s를 구분
...                      word)[0][0].strip("'")  # 매칭된 그룹 중 어간 부분만 추출
...          for word in phrase.lower().split()]  # 입력 문자열을 소문자로 바꾸고 단어 단위로 나눈 후 반복
...     )

>>> stem('houses')
'house'  
# "houses" → 끝의 s를 제거하고 "house"만 남김

>>> stem("Doctor House's calls")
'doctor house call'
# 1) "Doctor" → 소문자로 변환 → "doctor"
# 2) "House's" → s 제거 → "house"
# 3) "calls" → s 제거 → "call"
# 모두 합쳐서 'doctor house call' 반환
```














































































