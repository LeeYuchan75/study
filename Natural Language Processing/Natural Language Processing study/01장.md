### 자연어 처리 정의 

- **자연어** : 인간이 일상적으로 사용하는 언어

- **자연어 처리** : 자연어 처리란 컴퓨터가 자연어를 기반으로 이 세상에 관해 뭔가를 배우고 이해할 수 있도록 자연어를 변환하고 처리하여 활용하는 기술 및 분야

<br/>

### 자연어 처리의 필요성 

- 컴퓨터라는 것 자체가 이미 프로그래밍 언어를 기반으로 동작하지만 자연어는 이와 완전히 다름

    - 프로그래밍 언어는 형식 언어의 일종으로 문법에 근거하여 파싱(parsing)하고 이를 번역 또는 해석이 가능함
 
    - 자연어는 문맥이 중요하기 때문에 **문법에만 근거해서 완전히 해석할 수 없으며**, 문법에도 예외가 존재 ex: "배"라는 말이 과일, 동물, 배(boat) 등 상황에 따라 달라짐
 
    - 자연어의 해석을 위해서는 배경지식이 필요한 경우도 많음 
  
<br/>

### 자연어 처리 발전 과정 

- **초창기**

    - 1950~60년대부터 “컴퓨터가 텍스트 문서를 이해할 수 없을까?”라는 연구가 시작

    - 자연어 처리를 단순한 조건문/반복문, 문자열 매칭을 이용한 **패턴 기반 NLP**로 구현함. 즉, 예전 챗봇은 단순 규칙에 따라서만 행동
 
    - 예를 들어, 입력에 “hello” 같은 단어 있으면 → “안녕하세요”라고 답하는 **단순 챗봇**이였음
 
    - 이것을 정규식으로 사용은 가능, 하지만 패턴 기반 NLP는 특정 상황에서는 작동하지만, **그 외 상황에서는 무력함** 

    - 자연어 입력에 대한 의미를 컴퓨터가 파악하도록 하는 데는 **무리가 있음** (ex: “배고프다”와 “밥 먹고 싶다”가 같은 뜻이라는 못 알아챔)
 
    - 기초적인 패턴 기반 접근 방식은 **오타를 걸러낼 수 없고**, 다양한 축약어 등을 모두 표현하려면 많은 노력이 필요

<br/>

- **아이디어**

    -  유용한 자연어 처리를 위해서는 단순히 문자열의 패턴을 매칭하는 것이 아니라 **문자열의 의미를 기반**으로 매칭 혹은 해석이 가능해야 함
 
    - 표음문자의 경우 보통 단어 단위로 의미를 내포 -> 문자열을 문자 단위가 아니라 **단어 단위로 해석**하게 된다면 보다 의미 분석을 수월하게 할 수 있을 것이라고 추측함
    
    - 즉, "Hello" → 'H', 'e', 'l', 'l', 'o' 로 분석하는게 아니라, hello **그 자체로 의미를 학습**하게 하자는 것
 
    - 분석 결과를 **벡터**로 나타낼 수 있다면 벡터 공간에서의 연산을 통해 **다양한 작업을 수행 가능** -> 기계학습을 활용하기에도 좋음
 
    - **Bag-of-Words가 등장함**

<br/>

- **Bag-of-Words 역사**

    - 초창기에는 문서 검색에 사용 : 검색어를 입력 -> 많은 문서 중에서 관련 있는 문서를 찾아주는 것
 
    - 이후 문서 분류에 사용 : 스포츠, 정치, 경제 등등을 분류
 
    - 2000년대부터는 스펨 필터와 감성 분석에 사용 : 스펨 판단 및 영화 리뷰 긍/부정 분류
      
<br/>

### 초창기 간단한 챗봇 예시 

- 간단한 정규식으로 “hello/hi/hey” 같은 인사말이 입력에 있는지 확인

```ruby
>>> import re
>>> r = "(hi|hello|hey)[ ]*([a-z]*)"                                     # hi, hello, hey로 시작하고, 뒤에 공백과 알파벳이 올 수 있는 패턴을 만듦
>>> re.match(r, 'Hello Rosa', flags=re.IGNORECASE)                       # match : 문자열의 시작 부분부터 위에서 만든 정규식 패턴과 일치하는지 확인하는 함수
<_sre.SRE_Match object; span=(0, 10), match='Hello Rosa'>                # flags=re.IGNORECASE에 의해 대소문자 구분 x -> Rosa도 r의 규칙에 의해 match 가능
>>> re.match(r, "hi ho, hi ho, it's off to work ...", flags=re.IGNORECASE)
<_sre.SRE_Match object; span=(0, 5), match='hi ho'>
>>> re.match(r, "hey, what's up", flags=re.IGNORECASE)
<_sre.SRE_Match object; span=(0, 3), match='hey'>
```

<br/>

- 인사말 + 이름까지 매칭 (확장된 정규식)

```ruby
>>> r = r"[a-z]*(y|o|h)?ello|ok|hey|good[ ]?(morn[gin]{0,3}|afternoon|even[gin]{0,3})[\s,;:]{1,3}([a-z]{1,20})"  # 위 코드에서 r을 인사말과 이름을 감지할 수 있는 최소 패턴을 만든 것이고, 해당 r은 이것을 확장한 것 
>>> re_greeting = re.compile(r, flags=re.IGNORECASE)      # compile : 같은 정규식을 매번 해석하지 않고, 미리 번역된(컴파일된) 형태를 재사용이 가능함

>>> re_greeting.match("Hello Rosa")    # complie을 이용했기 때문에 ' re.match(r, 'Hello Rosa', flags=re.IGNORECASE)' 로 길게 쓰지 않고 간단한 코드 작성이 가능
<_sre.SRE_Match object; span=(0, 10), match='Hello Rosa'>

>>> re_greeting.match("Good morning Rosa")
<_sre.SRE_Match object; span=(0, 17), match='Good morning Rosa'>

>>> re_greeting.match("Good evening Rosa Parks").groups()
('Good evening', 'Rosa')

>>> re_greeting.match("yo Rosa")
<_sre.SRE_Match object; span=(0, 7), match='yo Rosa'>
```

<br/>

- if문으로 정중/무례 여부에 따라 응답이 다르게 함
  
```ruby
>>> my_names = set(['rosa', 'rose', 'chatty', 'chatbot', 'bot', 'chatterbot'])
>>> curt_names = set(['hal', 'you', 'u'])
>>> greeter_name = ''
>>> match = re_greeting.match(input())

>>> if match:
...     at_name = match.groups()[-1]
...     if at_name in curt_names:
...         print("Good one.")
...     elif at_name.lower() in my_names:
...         print("Hi {}, How are you?".format(greeter_name))
```

아래는 위와 같은 패턴기반NLP를 이용해서 1966년에 만들어진 규칙 기반 챗봇 ELIZA의 대화 예시이다

![System Resources](../../images/Natural%20Language%20Processing%20images/패턴기반NLP예시.png)

<br/>

### Bag-of-words

- **Bag-of-words**

    - 주어진 문장의 의미를 벡터로 나타내기 위해 **유의미한 단어들의 등장 횟수**를 벡터 내의 각 **자릿수**로 활용하는 방식
   
    - ex: “A bat and a rat..." 와 같은 문장이 나오면, A, a, and와 같은 **불용어를 제외**하고, 의미있는 단어인 bat과 rat을 카운트해서 **벡터로 변환**
 
    - **단점** : 단어들의 순서 및 문법 정보를 손상시킴 (짧은 문장은 괜찮게 동작, 하지만 긴 문장에서는 성능이 안 좋음)
 
    - ex : “개가 사람을 물었다” vs “사람이 개를 물었다” 를 보고 개와 사람과 관련이 있는 문장이라고만 파악 가능 -> 즉, 둘 다 동일한 주제를 가졌구나만 알 수 있다 
    
<br/>

### 매우 단순한 bag-of-words 구현 예시

- BoW (단어 빈도 세기)
  
```ruby
from collections import Counter                 # Counter : 단어 빈도수를 세는 라이브러리 

Counter("Guten Morgen Rosa".split())
# 결과: Counter({'Guten': 1, 'Rosa': 1, 'Morgen': 1})

Counter("Good morning, Rosa!".split())
# 결과: Counter({'Good': 1, 'morning,': 1, 'Rosa!': 1})
``` 

<br/>

- 단어 순서가 바뀌면 문장이 여러 개로 변함
  
```ruby
from itertools import permutations     # 파이썬의 조합/순열 라이브러리

[" ".join(combo) for combo in permutations("Good morning Rosa!".split(), 3)]  # 순열 튜플을 다시 문자열로 합침
# 결과:                                                                       # 예: ('Good','Rosa!','morning') → "Good Rosa! morning".
# ['Good morning Rosa!',
#  'Good Rosa! morning',
#  'morning Good Rosa!',
#  'morning Rosa! Good',
#  'Rosa! Good morning',
#  'Rosa! morning Good']
``` 

<br/>

- 문장이 길어지면 단어 순서 경우의 수가 팩토리얼로 폭증

    - 즉, BoW는 순서를 학습하지 못하므로, 정확한 뜻을 예측하기 어렵다는 것을 보여줌 
  
```ruby
s = """Find textbooks with titles containing 'NLP',
or 'natural' and 'language', or
'computational' and 'linguistics'."""

len(set(s.split()))
# 결과: 12

import numpy as np
np.arange(1, 12 + 1).prod()  # factorial(12)
# 결과: 479001600
```

<br/>

### bag-of-words 초기 극복 아이디어 

- **구문 트리** 사용

    -  문장의 **문법적 구조(syntactic structure)** 를 표현하는 도구
 
    -  초기에는 사람이 직접 문법 규칙을 일일이 작성.

    - ex : “-다”로 끝나면 동사일 확률이 높다

    - ex : “-에/에서/으로” 뒤에 오는 건 명사일 확률이 높다
 
- 구문 트리 예시 

![System Resources](../../images/Natural%20Language%20Processing%20images/구문트리예시.png)

<br/>

### 구문 트리를 이용한 NLP 파이프라인 

- **파이프라인** : 일련의 처리 과정이 순차적으로 이어진 것

- 챗봇에 대한 NLP 파이프라인 예시
    
    - 파싱: 특징 및 수치 자료 추출 -> 입력 문장에서 필요한 정보(단어, 품사 등)를 뽑음
   
    - 분석: 특징 추가 생성 및 결합 -> 뽑아낸 정보를 조합해서 더 의미 있는 표현을 만듦
   
    - 생성: 응답문 작성 -> 챗봇이 대답할 문장을 만듦

    - 실행: 대화 계획 관리 및 응답문을 선택하여 출력 진행 -> 여러 후보 중 적절한 답을 골라서 사용자에게 보여줌

<br/>

- ex 사용자 입력: "오늘 서울 날씨 알려줘"

    -  파싱 : 토큰화 → ["오늘", "서울", "날씨", "알려줘"] 후 품사 태깅 → 오늘(Noun), 서울(ProperNoun), 날씨(Noun), 알려줘(Verb)
 
        - **구문 트리를 사용**해서 품사를 태깅함  





