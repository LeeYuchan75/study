### 단어 출현 빈도를 활용한 벡터화

-  특정 문장이나 문서를 그 의미에 따라 벡터화하기 위한 방법 중 하나로써 **Bag-of-Words(BoW)** 를 활용 가능 

- 아래는 NLTK를 활용한 문서 토큰화를 한 뒤 파이썬 Counter 객체를 활용한 토큰별 출현 횟수 계산한 예시 코드이다

    - NLTK : 파이썬 NLP 라이브러리, BoW 실습에 활용된 도구 

```ruby
# NLTK의 TreebankWordTokenizer를 불러오기
from nltk.tokenize import TreebankWordTokenizer  

# 예시 문장 정의 (Harry가 더 빨리 상점에 갈수록 집에 더 빨리 도착한다는 의미)
sentence = """The faster Harry got to the store, the faster Harry, the faster, would get home."""

# 토크나이저 객체 생성
tokenizer = TreebankWordTokenizer()

# 문장을 소문자로 변환한 뒤 토큰화 실행
tokens = tokenizer.tokenize(sentence.lower())

# 토큰 출력
print(tokens)
# 출력 결과:
# ['the', 'faster', 'harry', 'got', 'to', 'the', 'store', ',', 'the', 'faster',
#  'harry', ',', 'the', 'faster', ',', 'would', 'get', 'home', '.']


# collections 모듈의 Counter를 불러오기 (토큰 빈도수 계산용)
from collections import Counter  

# 토큰 리스트를 Bag-of-Words 형식으로 변환 (각 단어의 등장 횟수를 센다)
bag_of_words = Counter(tokens)

# 가장 많이 등장한 상위 4개 단어 출력
print(bag_of_words.most_common(4))
# 출력 결과: [('the', 4), (',', 3), ('faster', 3), ('harry', 2)]
# - 'the'는 4번 등장
# - ','(쉼표)는 3번 등장
# - 'faster'는 3번 등장
# - 'harry'는 2번 등장
```
<br/>

- **코드 해석**

    - 가장 많이 출현한 토큰들 중 관사 ‘the’와 문장부호 ‘,’는 의미 해석에는 크게 도움이 되지 않음
 
        - 따라서 일반적인 경우에 **불용어 처리** 
     
        - 불용어를 제외하면 많이 등장한 단어는 faster, harry ->  어느 정도 문장의 의미를 대변할 수 있는 단어

<br/>

- **Bag-of-Words(BoW) 방식의 한계점**

    - 그러나 단어의 출현 횟수만으로 문장이나 문서를 벡터로 나타낸다면 문장, **문서의 길이가 제각각**이기 때문에 긴 문장에서와 짧은 문장에서의 벡터값 분포가 매우 달라짐
 
        - 어떤 짧은 문장은 5번 등장도 많은 반면 긴 문서는 1000번 정도는 나와야 많이 나왔다고 할  수 있음
     
        - **해결책** : **정규화**를 하여 **비율**로 표현
































































