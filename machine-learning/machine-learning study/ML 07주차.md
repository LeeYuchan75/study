![image](https://github.com/user-attachments/assets/89c8c498-b909-40c4-9701-9a505b81b383)## Decision Tree의 한계점

Decision Tree의 한계점은 바로 **편향-분산 트레이드오프 문제이다**

- 깊이를 얕게 만들면 → 모델이 단순해짐 → 편향 ↑

- 깊이를 깊게 만들면 → 모델이 복잡해짐 → 분산 ↑

<br/>

아래 깊이에 관계에 따라 특성을 나타낸 것인데 편향과 분산에 대해 개념을 복습하자 

편향 (Bias) : 모델이 정답에서 얼마나 벗어나 있는지, **예측이 일관되게 틀리는 정도**

분산 (Variance) : 데이터가 조금만 바뀌어도 예측이 크게 달라지는 정도, 즉 **모델의 민감도를 의미**

- 깊이가 얕으면(단순 모델): 높은 편향(bias), 낮은 분산(variance)

- 깊이가 깊으면(복잡한 모델): 낮은 편향, 높은 분산

<br/>

위의 특성을 보고 우리는 다음과 같은 질문을 할 수 있다 

이 트레이드오프를 원칙적으로 잘 조절할 수 있는 방법은 없을까?

즉, 모델을 조합해서, 보다 유연하게 분산을 줄이는 방법을 사용할 수 있지 않을까?

<br/>

위 질문에 대한 해결책이 바로 **Ensemble 이다**

Ensemble의 기본 아이디어는 여러 모델들을 조합하여 결과를 내는 것인데, 이 방법을 사용하면 다음과 같은 이점이 존재한다 

- 정확도 향상 : 여러 모델의 예측을 결합하면 개별 모델보다 더 나은 성능을 낼 수 있음

- 분산 감소 : 모델들이 서로 다른 실수를 하기 때문에, 평균을 내면 과적합 위험이 줄어듦 -> 불안정한 모델(예: Decision Tree)에 효과적

- 일반화 능력 향상 : 새로운 데이터에 대해 더 안정적이고 일관된 예측 가능

<br/>

Ensemble은 회귀와 분류에서 다음과 같이 사용된다

![스크린샷 2025-04-18 104148](https://github.com/user-attachments/assets/47cdfba6-5a7d-4b98-9fe7-d183222af398)

![스크린샷 2025-04-18 104154](https://github.com/user-attachments/assets/e7d30d72-7eed-4fc4-bade-04d87333ba18)


예를 들어 분류에서는 각 모델의 예측이 [1,1,0,0,1] 라면 아래 식에 의해 클래스 1를 출력한다 

![image](https://github.com/user-attachments/assets/c960de14-c12e-41ed-a58a-452aafae2c83)

<br/>

또한 아래와 가중치를 각 입력마다 정할 수 있는 방법도 있다 

![image](https://github.com/user-attachments/assets/ee3af97c-a511-41ba-bfea-2a0e5257817b)

맨 위에 식은 훈련 데이터로 알맞은 베타를 구한 뒤 그것을 활용하는 것이다 

두번째 식을 보면 g 베타 안에 모델들이 묶여 있는 것을 볼 수 있는데 

이때 g의 역할은 평가 데이터나 실전에 들어갔을 때, 입력마다 베타가 **실시간으로 바뀐다**

첫번째 식은 훈련 데이터 후 베타가 고정되어 있지만 두번째 식은 훈련 데이터 후 평가 데이터가 들어와도 동적으로 바뀐다 

이 개념을 사용한 것이 **Mixture of Experts(MOE) 이다**

<br/>

## Mixture of Experts(MOE)

![image](https://github.com/user-attachments/assets/f711eb06-87b3-4d30-8e97-c4bc0d820f3c)

MOE는 **입력 x**에 따라 어떤 모델을 더 신뢰할지 동적으로 가중치를 준다 

즉, 모든 데이터에 같은 가중치를 쓰는 게 아니라, 데이터별로 어떤 모델을 더 믿을지 정한다 

<br/>

## MOE & one hot 

MOE는 입력 x에 따라 어떤 모델을 더 신뢰할지 동적으로 가중치를 주는데 

이것을 one hot 벡터를 이용하면, 가중치가 가장 높은 모델만 1이 되고 나머지는 0이 된다 

이렇게 되면, 해당 입력 데이터를 제일 잘 처리할 수 있는 모델만을 선택하여 처리한다 

<br/>

## Ensemble Design Decisions

Ensemble를 설계 할 때 아래 두 가지 기준이 매우 중요하다 

- 기초 모델들을 어떻게 다양하게 만들까?

- 학습된 모델들을 어떻게 결합해서 하나의 예측으로 만들까?

즉, 다양성(Diversity) 확보가 핵심이다 

**모델들이 같은 실수를 하지 않아야 앙상블 효과가 크다**

그 이유는 아래 예시와 함깨 설명하도록 하겠다 

<br/>

## 동전 문제 예시 

다음 예시는 왜 같은 실수를 하면 안되는지 확률의 개념인 **독립**과 함께 설명한다 

![IMG_3101](https://github.com/user-attachments/assets/e0169e4d-4dfc-4303-8d00-054b3e714cd5)

위 예시에서 보면 3개의 모델 정확도가 모두 3/4이다 

만약 3개의 모델이 모두 동일한 i번째에서만 실수가 발생했다면(즉, 독립적인 실수가 아니라면) 정확도는 4/3이 나올 것이다

하지만 3개의 모델이 위 이미지와 같이 다 다른 곳에서 실수를 했다면 아래와 같은 공식을 유도할 수 있다

![IMG_3102](https://github.com/user-attachments/assets/301236c9-f848-48ee-a163-27df53b5bbaf)

위 공식을 해석하면 전체 확률에서 모두 다 틀릴 확률과 각 모델에서 하나만 틀린 확률을 뺀 것이다 

이 경우 정확도는 대략 0.84가 나온다 

이것을 직관적으로 해석하면 3개의 모델이 동일한 곳에서 실수가 발생했다는 것은 모델들이 같은 약점을 가지고 있는 것이고 

각각 다른 곳에서(독립적으로) 실수가 발생했다면, 서로가 서로의 약점을 보완해줄 수 있다 

<br/>

## Bootstrap & Bagging

다음은 Ensemble의 기법인 Bootstrap과 Bagging에 대해 소개하도록 하겠다 

<br/>

## Bootstrap

**복원 추출**로 데이터를 뽑는 과정

원래 데이터가 n개일 때, 복원 추출로 n개를 다시 뽑음

일부 데이터는 중복 포함, 일부 데이터는 전혀 안 뽑힘

![image](https://github.com/user-attachments/assets/d26232f3-0830-4d65-a49c-f0cb957fb080)

위 식은 복원 추출을 했을 때, 한 샘플이 한 번도 뽑히지 않을 확률이다 

<br/>

즉, 전체 데이터 중 약 36.8%는 포함되지 않다는 의미다 -> 포함되지 않는 데이터는 이후 평가 데이터로 활용

이 의미는 각 샘플마다 다양성을 확보할 수 있다는 것이다 

따라서 Bootstrap은 Ensemble에서 **데이터를 다양하기 만들기 위해 사용한다**

<br/>

<br/>

## Bagging 

Bagging은 Bootstrap Aggregating의 줄임말이다 

Bagging은 여러 개의 서로 다른 데이터셋으로(Bootstrap으로 뽑음) 훈련한 모델들을 병렬적으로 학습한 후, 결과를 평균 또는 투표로 결합하여 예측 성능을 향상시키는 기법이다

원래 데이터셋이 n개라 하더라도, 복원 추출(with replacement)로 n' 개를 새로 뽑는다 (중복 가능, 일부 샘플은 빠짐)

또한, Bagging은 특정 모델에 국한되지 않고, 어떤 모델이든 활용해서 다양한 앙상블을 구성할 수 있는 유연한 방식이다 

<br/>

따라서 Bootstrap과 Bagging이 Ensemble 기법에 사용되는 방식은 아래와 같다

1. Bootstrap을 통해 데이터셋을 다양하게 만듦 → 원래 데이터셋에서 중복 허용하여 여러 개의 서브셋 생성

2. 각 서브셋으로 모델을 따로 훈련시킴 → 예: 트리1, 트리2, 트리3, ..., 트리100

3. 각 모델의 예측 결과를 평균/투표로 결합 -> 회귀면 평균, 분류면 다수결 투표

이렇게 해서 분산은 낮추면서, 과적합을 방지할 수 있다

<br/>

## Bagging-based Ensemble

**핵심 개념**

여러 개의 부트스트랩 데이터셋(복원 추출)을 만들어 각각 독립적인 모델을 학습시키고, 그 결과를 평균 또는 투표로 결합하는 방법이다

<br/>

**Step 요약**

- Step 1: 원본 학습 데이터를 Bootstrap(복원추출)으로 여러 개 만듦

- Step 2: 각 데이터셋마다 모델 1개씩 학습

- Step 3 (선택): 검증 데이터로 각 모델에 가중치 줄 수도 있음 (아니면 그냥 평균)

<br/>

## Random forest

Random forest란 여러 개의 결정 트리(Decision Tree)를 학습시키고, 그 예측을 평균하는 앙상블 기법이다

Random forest가 좋은 이유는 일반적으로 깊은 트리는 정확하지만 분산이 큰 경향이 있는데 (데이터 조금 바뀌면 예측도 크게 바뀜)

여러 트리를 평균하면 → 불필요한(irrelevant) 분산을 상쇄할 수 있어서 **높은 성능을 유지하되 과적합 위험은 줄이는 효과가 있다**

Random forest에서 사용하는 두 가지 아이디어를 소개하겠다

<br/>

## Feature Randomness

이 방법은 트리의 각 노드 분할 시, **전체 feature 중 일부만 랜덤하게 선택해서 나누는 것이다**

예: 전체 feature 수 d라면, 약 루트 d개만 사용

이렇게 하면 트리들이 서로 다른 feature 조합을 사용해서 학습되어 **트리 간 상관(correlation)** 이 줄고, 다양성 증가

일부만 사용하는 이유는 만약 몇 개의 feature가 지나치게 강력하면, 전부 그걸로만 나눠서 모든 트리가 똑같아질 위험 있기 때문이다 

<br/>

## Unpruned 트리 사용트리 

이 방식은 가지치기(pruning)를 하지 않겠다는 의미이다 

이렇게 하면 개별 트리는 복잡하고 분산이 커지게 된다는 단점 때문에 걱정할 수 있지만,

**여러 트리를 평균내면 분산이 상쇄되어 강한 앙상블 효과**가 발생하기 때문에 문제가 되지 않는다

<br/>

## 예시 

![image](https://github.com/user-attachments/assets/1a45d38b-f714-496f-91dc-d8dd09827766)

<br/>

## Boosting

Boosting의 핵심 아이디어는 **약한 모델을 강한 모델로 바꾸자는 것이다**

오류율이 50프로보다 낮다면, 이것을 조합하여 더 강한 모델을 만들 수 있다 

Boosting에서 사용하는 알고리즘 중 가장 대표적인 AdaBoost를 소개하겠다 

<br/>

## AdaBoost 

AdaBoost : **여러 개의 약한 모델(weak learners)** 을 반복적으로 학습하면서 조합하여 **점점 더 강력한 모델(strong learner)을 만드는** Boosting 알고리즘이다 

Bagging과 유사하게 AdaBoost도 여러 모델을 조합하는 상위 알고리즘 (meta-algorithm) 이지만 **차이점이 존재한다**

- Bagging: 데이터 샘플을 무작위로 뽑음 (복원추출)

- Boosting: **틀린 샘플에 가중치를 더 줘서** 다음 모델이 그것에 집중하게 함

<br/>

AdaBoost는 매 반복마다 데이터 샘플에 **가중치(weight)를 다르게 부여함**

- 잘 맞춘 샘플 → 가중치 낮춤 (downweight)

- 틀린 샘플 → 가중치 올림 (upweight)

이렇게 하면 모델이 점점 약한 샘플에 집중하게 되고 이것이 Boosting의 핵심 전략이다 

<br/>

또한, AdaBoost에 사용할 수 있는 기본 모델은 다음 조건을 만족해야 함

- **high-bias / low-capacity** : 단순한 모델이어야 함 (예: 깊이 제한 있는 결정 트리, 선형 모델 등)

- **샘플 가중치 반영 가능** : 각 샘플마다 부여된 weight를 학습에 반영할 수 있어야 함

- **분류(classification)에 최적화됨** : 일반 회귀보다 분류 문제에 잘 맞음

강의에서 Ada가 회귀로 사용이 어렵다고 했지만.

하지만 이후 선형 회귀 관점으로 분석하면 adaboost도 선형 회귀에서 사용할 수 있다고 언급함

<br/>

## AdaBoost의 Input & Output 구조

- **Training dataset Z** : 학습에 사용할 전체 데이터셋

- **Train(Z, w)** : 각 데이터 샘플마다 가중치 w를 부여해 학습 가능한 알고리즘

- **Hyperparameter T** : 총 몇 개의 약한 모델을 만들 것인지 (반복 횟수)

<br/>

![image](https://github.com/user-attachments/assets/ddfb41a9-dcca-4d71-a1a6-0a8b5c85cef0)

- **ft(x)** : t번째 약한 모델

- **𝛽t** : 그 모델의 신뢰도(가중치)

<br/>

## AdaBoost 알고리즘

![image](https://github.com/user-attachments/assets/1a740768-db59-453a-b458-1035aba71547)

위 알고리즘의 전체적인 흐름을 보자면 

- w₁ = (1/n, ..., 1/n) : 모든 샘플에 가중치를 부여

- for t in {1,...,T} : t개의 샘플을 한번씩 확인

- ε_t ← Error(f_t, Z, w_t) : 현재 모델이 얼마나 틀렸는지 계산 -> 틀리면 가중치의 값이 크게 나옴 

- β_t(신뢰도) = (1/2) * ln((1 - ε_t) / ε_t) : 에러율이 낮을수록 → β_t가 커짐 (이것은 중요해서 아래에 따로 설명함) 

- w_{t+1,i} ∝ w_{t,i} * exp(-β_t * y_i * f_t(x_i)) : 틀린 샘플에 더 집중하도록 유도 (이것도 아래에서 설명), 즉 가중치 역할

- F(x) = sign(Σ β_t * f_t(x)) : 모든 약한 모델의 예측을 가중 평균해서 최종 결정을 내림, 즉 모든 가중치 x 모델를 더해서 부호가 0보다 크면 1로 예측, 0보다 작으면 0으로 예측함 

<br/>

위 코드의 핵심이 바로 아래 두 코드이다 

- β_t(신뢰도) = (1/2) * ln((1 - ε_t) / ε_t)

- w_{t+1,i} ∝ w_{t,i} * exp(-β_t * y_i * f_t(x_i))

<br/>

우선, β_t = (1/2) * ln((1 - ε_t) / ε_t) 함수를 실제로 그려보면 다음과 같다 

x 축 : ε_t(요류율) ,  y 축 : β_t(신뢰도)

![image](https://github.com/user-attachments/assets/a73eb134-86cf-46a1-b836-f1709e710594)

이것을 해석하면 ε_t이 작을수록 β_t의 값이 커지고, ε_t가 클수록 β_t값은 작아진다 

이후 다음 코드인 w_{t+1,i} ∝ w_{t,i} * exp(-β_t * y_i * f_t(x_i))에서 

e의 지수인 y_i * f_t(x_i) 이 부분을 보자  

이 값의 의미는 y_i(실제값) 과 f_t(x_i)(예측값)의 곱을 의마한다. (값은 +1 과 -1만 존재, ex: 어떤 문제가 실제로 정답 = 1,  그러나 모델은 틀렸다고 판단 = -1)

즉, 실제값과 예측값이 동일하면 (모델이 예측에 성공하면) +1, 틀리면 -1이 되어 **이 두 값의 곱은 결국 지수의 부호를 결정한다**

<br/>

다시 exp(-β_t * y_i * f_t(x_i)) 이 코드를 살펴보면 지수부분에 마이너스가 있는 것을 확인할 수 있다 

따라서 예측이 틀리면 마이너스 x 마이너스(예측 실패)가 되어 지수가 양수가 되어 값이 커지고 마이너스 x 양수(예측 성공)를 하면, 값이 작아진다 

<br/>

또한, 가중치를 부여하는 코드를 보면 t+1 번째 가중치가 t번째 가중치는 서로 연관이 있다(지수 함수를 상수로 보면 서로 비례함)

이것은 f1이 틀린 샘플을 f2가 더 집중하고, f2가 틀린 샘플을 f3가 더 집중하는 형식이다 

다음 모델은 이전 모델이 틀린 샘플에 더 집중하며, 연속된 모델들이 서로 보완적으로 학습하게 된다 

## 진행 과정 

아래 진행과정을 살펴보면 틀린 샘플의 원의 크기가 커지는 것을 볼 수 있고, 이것이 총 T번 반복이 되면,

![스크린샷 2025-04-18 132650](https://github.com/user-attachments/assets/6300dba6-3c1c-4a37-8364-cc75181767e8)

![스크린샷 2025-04-18 132707](https://github.com/user-attachments/assets/4e2dca2b-7025-4d61-b817-6aadf9eb6176)

![스크린샷 2025-04-18 132717](https://github.com/user-attachments/assets/3f5925a6-f028-4f14-bd87-5a62a502987c)

**이미지 해석**

- 큰 파란 원 : 예측이 자주 틀려서 가중치가 높아진 샘플

- 많은 선이 겹친 영역 : 여러 모델이 같은 쪽으로 예측 → 강한 결정

- 파란 음영 영역 : 최종 앙상블 모델이 파란 클래스라고 강하게 판단하는 영역

이 영역은 결국 최종 모델이 ‘이 영역 안의 샘플은 파란색 클래스(+1)’로 분류할 가능성이 높다는 뜻이다 

<br/>

## AdaBoost Summary

**장점**

- 빠르고 구현 쉬움

- 하이퍼파라미터 거의 없음 (단, 반복 횟수 T만 조절)

- 약한 모델에도 잘 작동

<br/>

**단점**

- 노이즈/이상치에 민감함 (잘못 예측된 샘플에 가중치 부여하기 때문)

- 병렬처리 불가능 (반복적으로 모델 학습해야 하므로)

- 복잡한 모델에 비해 성능 향상 크지 않을 수 있음

- 분류 문제 전용 (회귀엔 적합하지 않음)

<br/>

**AdaBoost and Overfitting**

일반적인 이론상으로는, T가 무한히 커지면 모델이 복잡해지고 과적합할 수 있음

**하지만 실제에서는 과적합이 잘 일어나지 않음**

그 이유는 AdaBoost는 반복해도 틀린 샘플에 집중하긴 하지만, 모델 전체를 오버하게 하진 않기 때문 -> 알고만 넘아가기 

<br/>

## 기울기 관점의 Boost

Boosting도 경사하강법처럼 기존 모델 + 보정값 구조로 반복 업데이트를 수행한다 

![image](https://github.com/user-attachments/assets/276a416b-0767-4d1c-a898-c8ca9e56b4c4)

위 식과 같이 Boosting을 경사하강법으로 표현할 수 있다 

위 식에서 β의 값을 1로 고정하고, Ft(xi)를 이항하면, 아래와 같다 

![image](https://github.com/user-attachments/assets/cfbea8c8-ed4b-497a-836f-e11204299278)

즉, 위 식에서 말하고자 하는 것은 **모델이 현재 오차를 줄이는 방향으로 다음 모델을 학습한다는 것이다**

위 식에서 yi - Ft(xi)가 기울기를 의미하는 이유는 아래와 같다 

![image](https://github.com/user-attachments/assets/0cc06cd7-b963-444a-9f32-21f540da7696)

Boosting은 음의 그레이언트(손실이 줄어드는 방향)을 사용하므로 부호만 바꿔주면 해당 식은 기울기와 같다 

<br/>

## 과정 요약 

- Step 1: 현재 모델이 틀린 부분(오차, 잔차)을 파악함 → "지금까지의 모델이 어떤 데이터를 잘못 예측했는지 확인"

- Step 2: 새 모델은 이 오차를 예측하도록 학습됨 → "오차만 집중해서 공부하는 약한 모델 하나 생성"

- Step 3: 이전 모델에 이 새 모델을 더해서 보정 → "기존 모델 + 오차 보정 모델 = 더 좋은 모델"









































































































