## Bias-Variance

선형회귀에서 특징맵을 사용할 경우 보편적으로 차원이 증가하면 

**capacity**(모델 용량 : 데이터를 학습하고 표현할 수 있는 능력)와 **variance 가** **증가하고**  **bias는 감소하여 과적합의 가능성이 높아짐**

여기서 주의해야하는 것이  **선형 함수의 차수는 β가 결정하기 때문에** 특징 맵을 사용해서 큰 차수의 함수를 표현할 수 있지만 **여전히 선형 함수라는 것이다**

따라서 특징맵을 사용하면 선형 회귀가 더 잘 맞추지만 선형함수가 변하지 않기 때문에 bias는 상대적으로 감소하는 경향을 있다 

<br/>

따라서 편향과 분산의 밸런스를 맞추며 특징맵을 구성하는게 중요함 

<br/>

또한 기존에 존재하는 훈련 데이터의 양보다 더 많은 훈련 데이터가 들어갈 경우 

**편향은 유지되고 분산과 MSE가 낮아지는 경향이 있다**

예를 들어 집값을 예측하는 상황에서 우리가 간단한 직선(linear regression) 모델을 선택했다고 가정하자 

<br/>

실제 데이터는 곡선 형태(비선형)로 나타나지만, 이 모델은 데이터를 **직선으로만 나타낼 수 있는 한계**를 가지고 있다

예를 들어, 집값은 특정 평수에서는 빠르게 증가하다가 어느 순간부터 증가율이 둔화되는 패턴을 보일 수 있다 

이 직선 모델은 실제 데이터를 잘 표현하지 못할 가능성이 크다. 이런 한계는 편향(Bias)에서 비롯된 것으로, **데이터를 더 많이 추가하더라도 직선 모델로는 곡선 패턴을 잘 표현할 수 없음**

<br/>

**즉, 데이터의 수가 많아져도 편향이 좋아지거나 나빠지지 않고 그래도 유지됨**

<br/>

하지만 데이터가 많아질수록 데이터가 충분히 많아지면, 모델은 이상치나 노이즈에 덜 민감해진다.  (만약 데이터가 적다면 모델이 이상치(outlier)와 노이즈를 포함한 패턴까지 모두 학습하려고 함)

모델은 데이터의 "전체적인 경향"을 더 잘 파악하게 되어, 안정적인 예측을 하게 됨

**따라서 분산은 낮아짐**

<br/>

## Bias & Variance

편향이 낮아진다는 의미 : 모델이 실제 데이터의 패턴(현실)을 더 잘 표현할 수 있게 되어, 단순한 가정에서 벗어나 복잡한 관계를 더 잘 학습한다는 뜻

**쉽게 말해, 모델이 현실과 더 가까운 결과를 만들어내는 상태**

<br/>

분산이 낮아진다는 의미 :  모델이 훈련 데이터의 작은 변화(노이즈)에 덜 민감해지고, 더 일관되고 안정적인 예측을 한다는 뜻

**즉, 훈련 데이터가 바뀌어도 모델의 결과가 크게 흔들리지 않는 상태를 의미**

<br/>

## As the data size grow:

Generalization Error (일반화 오차) :  모델의 예측이 얼마나 정확한지를 나타내는 지표로, 보통 **편향(Bias)** 과 **분산(Variance)** 의 합으로 설명

**즉, Generalization Error은 분산과 오차의 합으로 추측가능**

**데이터 사이즈가 증가할수록 Generalization Error는 bias에 지배적임**

데이터가 많아질수록 모델은 더 많은 패턴을 학습할 수 있기 때문에, **분산(Variance)** 은 줄어든다.

그러나, **편향(Bias)** 은 모델의 복잡도에 의존하며, 데이터의 양과는 큰 관계가 없음. 즉, 데이터셋이 커지면, 일반화 오차에서 **편향**이 주요한 요인이 됨

<br/>

## L2 Regularization

![스크린샷 2025-03-23 125508](https://github.com/user-attachments/assets/6b200139-efd8-4cd7-9e61-ce2c6f345ddb)

정규화 :  모델의 **과적합(overfitting)** 을 방지하기 위해 **loss function에 패널티를 추가하는 기법**

**전형적으로 정규화는 train data와 관계 없이 가중치만 판단하므로 data와 독립적이다**

<br/>

## Why does it help?

**1. Simple 함수 유도**

L2 정규화는 모델이 간단한 함수를 학습하도록 유도함. 여기서 말하는 간단한 함수란, 과도하게 복잡한 모델(예: 지나치게 큰 가중치)을 피하고, 모델이 적당히 평탄한 형태로 학습되도록 한다는 의미

<br/>

**2. 가중치 조절**

L2 정규화는 가중치 파라미터 β를 0에 가까운 값으로 밀어넣는다.

L2 정규화는 손실 함수에 가중치의 제곱을 추가하여, 모델이 학습하는 동안 가중치가 너무 커지지 않도록 제한함 

이를 통해 모델은 간단한 형태의 함수에 가까워진다.

모델이 훈련 데이터에 맞추려고 할 때, **모든 가중치를 적당히 작은 값으로 압축하는 효과를 주어**, 모델이 과도하게 복잡해지지 않도록 함

<br/>

**3. λ의 역할**

**λ** 는 정규화 강도를 결정하는 하이퍼파라미터이다

λ가 커질수록 정규화의 효과가 강해져, 모델의 가중치가 더 많이 감소하게 됨

λ → ∞ : λ가 매우 커지면, 모델은 가중치가 0이 되도록 강제로 학습하게 됨 이 경우, 모델의 복잡도는 최대로 줄어들고, 결국 모든 가중치가 0이 되어 모델이 단순화된다 

즉, λ 증가 -> regularization 증가 -> underfitting 

λ 감소 -> regularization 감소 -> overfitting

<br/>

## 가중치의 의미 

가중치가 높다는 것 :  **모델이 특정 특성에 매우 민감하게 반응한다는 의미** 즉, 데이터의 작은 변화에도 모델의 예측이 크게 달라짐 -> 과적합

가중치가 낮다는 것 : **모델이 각 특성에 대해 덜 민감하게 반응한다는 의미** 즉, 모델이 훈련 데이터의 세부 사항에 과도하게 맞춰지지 않고, 더 일반적인 패턴을 학습함. 또한 가중치가 작을수록, 모델의 용량(capacity) 즉, 모델이 표현할 수 있는 기능의 범위가 제한됨 

<br/>

## L2 Regularization

![IMG_3060](https://github.com/user-attachments/assets/36fd917b-54bb-44d3-80da-91c397d0142b)

<br/>

P(βj)의 의미는 해당 값을 가질 확률이다 

즉, L2 정규화는 모델의 **가중치(𝛽)의 값을 0에 가깝게 유지하려는 성향을** 가진다

가우시안 함수에서 화살표로 표시한 부분의 확률은 0.1과 0.2로 표시됨

L2 regularization 에서는 0.1로 표시된 부분보다 0.2로 표시된 부분을 2배 더 선호함 

따라서 더 큰 값(x값 기준)은 데이터 적합 항(MSE)에 대해 훨씬 더 나은 경우에만 모델에 선택

![IMG_3059](https://github.com/user-attachments/assets/56f38a21-3531-4b09-97d8-10a247c819a2)

<br/>

**λ**는 정규화 강도를 조절하는 하이퍼파라미터로, **편향(bias)** 과 **분산(variance)** 간의 트레이드오프를 조절함

**Capacity와 λ는 반비례 관계**

<br/>

## 문제 

정규화 후 새로 구한 파라미터 𝛽에 대해, 정규화 이전과 비교했을 때 그에 해당하는 L(β;Z) 값은 더 작아지는가 커지는가 

**답은 커진다**

손실 함수에 정규화가 없는 경우 β가 크더라도, 예측이 잘 되면 MSE는 작아졌다. 

하지만, 정규화를 포함하여 손실함수를 만들면, β가 너무 커지지 않도록 제한을 하며 MSE를 계산하므로, **손실 함수에 제약이 생겨 과적합을 방지한다**

즉, 정규화 후에는 Loss 값이 커지지만, **이것을 안좋게 생각할 필요는 없다**

우리의 목표는 **test에서 잘 작동하면 되는 것이기 때문에** 손실 값이 조금 높아져도 test에서 잘 되면 문제 없다 

<br/>

## Basic Cross Validation Algorithm (Hyper-parameter Tuning)

목적 : 모델의 일반화 성능(새로운 데이터에서의 성능)을 더 정확히 평가하고, 최적의 하이퍼파라미터를 선택하기 위함 (L2 정규화의 최적의 λ값을 찾기 위함)

최적의 방법: 데이터셋을 훈련(train) 세트와 검증(val) 세트로 나누고, 검증 세트에서 최적의 하이퍼파라미터 선택

과정 

1. **데이터셋을 나눈다** : 주어진 데이터를 훈련 데이터(모델을 학습하는 데 사용)와 검증 데이터(모델의 성능을 평가하는 데 사용)로 나눔

2. **검증 세트에서 하이퍼파라미터를 선택한다** : 모델을 학습할 때 사용하는 하이퍼파라미터(예: 학습률, 배치 크기 등)를 검증 세트를 사용해서 최적화함. 즉, 여러 하이퍼파라미터를 시도해보고, 검증 세트에서 가장 잘 작동하는 하이퍼파라미터 값을 선택하는 것

3. **재학습** : 선택된 최적의 하이퍼파라미터를 사용하여, 훈련 데이터(𝑍train)에서 최종 모델을 다시 학습

검증 세트는 실제 테스트 세트와는 다르며, 모델을 훈련시키고 하이퍼파라미터를 선택하는 데만 사용됨. 이 세트는 실제 테스트 데이터와는 분리되어 있기 때문에, 모델이 과적합되지 않도록 도와준다

**또한 train data가 너무 적다면, val data와 합칠 수 있음**

<br/>

## Wrong Hyper-parameter Tuning 

잘못된 튜닝 방법

1. 100% 훈련 데이터 : 과적합 위험성

2. 훈련 + test : 결국엔 test도 학습하게 되어 cheating

<br/>

## Cross Validation Hygiene

테스트 데이터는 하이퍼파라미터 선택이나 모델 설계에 사용하면 안 됨. 오염된 테스트 데이터의 성능 평가 결과는 신뢰할 수 없다

<br/>

## K-fold Cross-Validation

![image](https://github.com/user-attachments/assets/47364c04-c7f5-4b64-8f01-12cf47a03d7a)

<과정> 

1. **데이터 분할** : 전체 데이터 Z를 **훈련 데이터 (Z_train)** 와 **테스트 데이터 (Z_test)** 로 나눔

2. **훈련 데이터 재분할**: 훈련 데이터를 k개의 서로 겹치지 않는 검증 세트 (Z_val_s)와 나머지 훈련 세트 (Z_train_s')로 나눔

3. **평균 검증 손실 기반 최적화**: k번 반복해 검증 손실값을 계산하고, **평균 검증 손실이 가장 낮은 하이퍼파라미터 λ** 를 선택함

**즉, L2 정규화에서 최적의 λ를 찾기 위함**

위 과정에서 k번 실행 후 평균 검증 손실값이 가장 작은 하이퍼파라미터를 최적의 값으로 설정한 뒤, 이 하이퍼파라미터를 사용해 전체 훈련 데이터로 최종 모델을 학습함

<br/>

## 개념 정리 

1. **hyper-parameter** :  머신러닝 시스템의 속성 또는 설계 선택 사항으로, 사용자가 사전에 설정해야 하는 값

2. **Cross-validation** : 이러한 하이퍼파라미터를 선택하기 위한 일반적이고 체계적인 시행착오 절차이다

<br/>

## 손실함수 전략 

## Strategy 1 : Closed-Form Solution

![IMG_3066](https://github.com/user-attachments/assets/9e19323a-42c1-4dab-8a9e-4f20c969b470)

위 과정과 같이 대수적인 연산을 통해 최적화를 하는 전략이다 

해당 전략에는 다음과 같은 문제점이 존재한다

<br/>

## 문제점 1 : data의 수 < dimension 수

feature의 수가 데이터의 수보다 많으면, 방정식의 유일한 해(solution)를 찾지 못할 수 있다

따라서 아래와 같은 전략으로 해결할 수 있다

1. 특징의 수(d)를 줄여서 d≤n이 되도록 함

2. 데이터를 추가적으로 수집해서 데이터의 수(n)가 특징의 수(d)보다 많아지도록 (d≤n) 함

두 전략 모두 데이터의 수가 차원의 수보다 더 큰 방향으로(d≤n) 진행함

<br/>

## 문제점 2 : feature 중복 

특징 간 선형 종속성이 있으면 역행렬을 계산할 수 없어 고유한 해를 얻기 어렵다

이 경우에는 선형 종속성을 가진 특징을 제거하는 방향으로 문제점을 해결한다 


<br/>

## Closed-Form Solutio의 본질적 문제 

위 2가지 문제점이 해결한다해도 또 다른 문제가 존재한다 

<br/>

## 본질적 문제1 : 𝑋𝑇𝑋의 역행렬 시간 복잡도 : 𝑂(𝑑^3)

예를 들어 d = 10^4 이라면 (d는 feature를 의미), 시간 복잡도는 O(10^12)에 이르러 사실상 계산이 매우 어렵거나 불가능하다 

**특징이 많아지면, 이 행렬을 메모리에 저장하는 것조차 어려워진다. -> 많은 메모리도 소요됨**

<br/>

## 본질적 문제2 : ill-conditioning

Ill-conditioning : 𝑋𝑇𝑋가 역행렬을 잘 구할 수 없는 상태

역행렬을 구하기 위해서는 determinant를 사용해야한다

determinant는 행렬의 열들이 독립적일 때 크고, 종속적이면 작아지는 경향이 있어서 특징 간 유사성이 높으면 determinant는 0에 매우 가깝게 되어, 행렬이 거의 역행렬을 갖지 못하는 상태가 된다 

**또한, 아래 예시와 같이 분모가 너무 작아져서 분산이 커지게 되는 문제도 발생한다**

![image](https://github.com/user-attachments/assets/f8a7afb3-8cfc-4152-b4bb-d20c36e2870b)

<br/>

## Strategy 2 : Gradient Descent

먼저 위 전략을 설명하기 전, 두 가지 탐색 방법에 대해 소개함

**1. Global search** : 최적의 𝛽를 찾기 위해 무작위로 값을 다양하게 선택하고, 이 중 가장 좋은 결과를 선택하는 방법

**이전 값과 현재 값 간의 연관성 없이 독립적으로 값을 선택하기 때문에, 구조가 없고 차원이 증가할 수록 시간이 많이 소요됨**

<br/>

**2. Local search** : 초기값 β에서 시작하여 조금씩 변화를 주며 최적의 값을 찾아가는 방법

**이전 값과 현재 값이 서로 연관이 있음**

![image](https://github.com/user-attachments/assets/8a6dd5c0-7a5f-415d-a5d5-90495603168a)

위 식에서 기울기를 빠르게 변화하는 𝛽에 대한 함수를 찾아가는 방향으로 진행되고, 마이너스(-)는 기울기를 0으로 만들기 위함이다. 

𝛼: 학습률(learning rate)

∇𝛽𝐿(𝛽): 손실함수의 기울기(gradient)

<br/>

**또한, β의 각 성분(β1 ~ βk)을 업데이트 할 때, 전체 기울기를 계산한 후 한꺼번에 업데이트해야 한다**

```ruby
예시 설명

1. 먼저 ∇L에서 β1의 기울기를 계산 → 그리고 β1을 바로 업데이트
2. 그다음 β2의 기울기를 계산 → 근데 이때 β1은 이미 바뀐 상태!
```

**β의 이동을 반복하며 반응이 없을 경우 최종 결과에 도착했다는 의미**

![image](https://github.com/user-attachments/assets/9115fd4d-bd7c-48da-8d3f-6eb6bdcee9ec)

위 이미지와 같이 실무에서는 global minimum 을 찾는 것이 너무 어렵거나 계산량이 매우 많아 비효율적이기 때문에, 빠르게 접근 가능하고 성능도 나쁘지 않은 local minimum을 찾는 방식을 선호

**시작 위치를 바꾸면 방향도 바뀜**

<br/>

아래 첫번째 공식은 손실 함수가 어떤 방향으로 진행되는지를 확인하기 위해 미분을 이용한 것이다 

![image](https://github.com/user-attachments/assets/d62f5aee-5921-4033-aa6e-fa09ad66f26e)

**최적의 β를 찾을 때, 영향을 주는 것은 β와 input feature 이다**

위 공식에서 오른쪽 상단 부분은 속미분의 음수가 존재하지만 생략했다는 의미

위 내용에서 중요한 점은 gradient = β error x input feature(기울기는 β의 오차와 그 input feature의 곱이다)

<br/>

또한, (yi - βTxi)^2의 미분이 의미하는 것을 이해하기 위해 고등과정 미분 개념을 복습해보자 

![스크린샷 2025-04-22 202230](https://github.com/user-attachments/assets/03727e65-2398-454a-ad5d-1f370f5e68ce)

위 과정을 보면 (β-3)^2의 미분값이 0이 되는 값은 β = 3 인데 β를 5로 예측하면 값이 4가 나온다 

따라서, 미분 값이 0이 되기 위해서는 **반대 방향인 -4만큼 이동을 해야 한다**

<br/>

이것을 적용하여 다시 이미지 공식에 적용해보자 

![combined_gradient_example_v2](https://github.com/user-attachments/assets/dfbc56f3-275a-471b-89b7-061beade36a3)

위의 과정을 반복하며 β1 ~  βk 까지 손실함수를 최적화하는 방향으로 진행된다 

<br/>

## 입력값이 클 때 예시 

![image](https://github.com/user-attachments/assets/43197d60-2cac-4a76-a85e-8b517ed3a55a)

<br/>

## 오차가 클 때 예시 

![IMG_3067](https://github.com/user-attachments/assets/ef3dc760-74b6-4bce-9871-de3d91d524cc)

<br/>

**최적화가 완료되는 과정에서 gradient가 0인 것이지 Loss function 이 0인 것은 아님** 

<br/>

## SGD (Stochastic Gradient Descent)

SGD의 기본 아이디어는 **'모든 데이터를 평균내는 대신, 그냥 하나의 샘플을 랜덤으로 골라서, 그걸로 기울기를 추정해도 되지 않을까'** 의 관점에서 출발

![image](https://github.com/user-attachments/assets/8e531ddf-26b7-4edd-bb53-e413e43b8d5d)

<br/>

**1. Batch Gradient Descent (batch 생략하고 GD라고도 부름)**

배치 경사 하강법은 일반적인 경사 하강법으로 SGD와 달리 전체 데이터를 여러개에 샘플로 나눠서 모두 사용

장점 : 정확하고 안정적하지만,

단점 : 느림 (데이터가 클수록 계산량 많음)

<br/>

**2. Stocastic Gradient Descent**

**매 반복마다 하나의 샘플을 무작위로 뽑아 기울기를 계산**

장점 : 빠름

단점 : sample 하나에 대해서만 내려가기 때문에 상대적으로 잘 내려가지 못함. 하지만 여러 번 반복하면 평균적으로는 좋은 방향으로 이동

그때 선택한 샘플 하나의 손실 함수를 줄이는 방향으로 이동한다. 즉, 아래 예시와 같이 반복할 때마다 사용하는 손실 함수가 다름 (i번째 손실함수)

![IMG_3068](https://github.com/user-attachments/assets/42295938-5640-4c3b-8d53-fb25bb0ca496)

<br/>

딥러닝에서는 데이터가 매우 크기 때문에 GD, SGD가 다 성능이 안 좋음

-> **미니 배치 SGD 사용**
 
<br/>

## Learning rate 𝛼

![스크린샷 2025-04-04 210705](https://github.com/user-attachments/assets/ce4de7d5-0306-4fe6-9ecc-b27894b45573)

**그래프 해석**

**1. 왼쪽: GD (Gradient Descent)**

파란 선은 등고선, 즉 손실 함수의 높이 수준

붉은 점: GD의 이동 경로

매우 부드럽게, 일정한 경로로 **최저점(minimum)**을 향해 이동

설명: “언덕을 꾸준히 내려가는 것처럼 걷는다”

<br/>

**2. 오른쪽: Stochastic GD**

같은 손실 지형이지만, 각 스텝마다 오르내림이 있음

이는 데이터 하나에 기반한 noisy한 기울기 때문

**→ 경로가 덜 안정적, 좀 더 요동침**

설명: “매번 약간 흔들리는 언덕을 걷는 것과 같다”

<br/>

SGD의 진동을 줄이고 수렴을 안정화 시키기 위해 학습률 𝛼를 위와 같이 정의함 

**위 공식은 반복이 진행될수록 𝛼가 작아짐 → 파라미터 업데이트 크기도 작아짐 -> 진동 수렴 감소**

<br/>

다음은 학습률 𝛼의 크기에 따라 변화하는 모습을 보여줌 

![image](https://github.com/user-attachments/assets/3ffd6a6a-6d79-4e75-b854-6df0ff7a7ad3)

<br/>

## 정리 

**Closed-form solution**

장점 : hyper-parameter 가 없다. 수학적으로 한 번에 해를 구할 수 있음

단점 : 데이터의 수나 차원이 커지면 속도가 느리다(시간 복잡도가 매우 큼)

<br/>

**Gradient descent**

장점 : 큰 데이터에도 확장 가능. 수천~수백만 개 샘플에도 적용 가능 (특히 미니배치, SGD 활용 시)

단점 : 학습률 𝛼를 잘 설정해야 함 (튜닝 필요). 너무 크면 발산, 너무 작으면 느림, 반복 횟수 설정도 필요



