## Demand paging

**Demand paging** : 메모리 절약을 위한 기법으로, **필요한 페이지만 메모리에 올리는 방식**

Demand paging에서는 페이지를 필요할 때만 메모리로 가져온다

즉, **절대 접근되지 않는 페이지는 물리 메모리에 절대 로드되지 않는다**

<br/>

**Lazy swapper** : 페이지가 필요하지 않으면 절대 메모리에 가져오지 않는 방식

페이지를 다루는 swapper를 pager라고 한다. 

**Pager와 lazy swapper는 같은 의미**로 사용하지만, **swapper**는 일반적으로 **전체 프로세스**를 다루고, **pager**은 **개별 페이지**를 다룬다.

**page라는 용어**가 swap이라는 용어보다 더 **보편적으로 사용된다**

![IMG_3302](https://github.com/user-attachments/assets/d5dfb1ba-4fa6-45fb-b7ee-a690b714c3b7)

<br/>

## Valid & Invalid Bits

**Valid & Invalid Bits** :페이지마다 **해당 페이지가 현재 메모리에 있는지 아닌지를 표시**하는 비트

표시는 v와 i로 표시한다 

- **v** : **valid**라는 의미로 **해당 페이지가 메모리에 있음**

- **i** : **invalid**라는 의미로 **해당 페이지가 메모리에 없거나 접근이 illegal한 상황** → **접근 시 page fault 발생 또는 접근 불가**

**invalid**의 경우 단순히 메모리에 없는 것 뿐만 아니라 **접근 자체가 불법인 상황도 고려해야한다**

![IMG_3303](https://github.com/user-attachments/assets/66b864b8-1dd0-4a97-99fd-c572cdf3dcb3)

- **초기에는 모두 invalid bit**

- 이후 요청을 받으면 **page를 메모리에 올린 뒤 invalid bit -> valid bit로 변경**

- 이렇게 참조가 된 것만 메모리에 올리고 **나머지는 메모리에 올릴 필요 없음 -> Demand paging 방식**

<br/>

invalid가 발생하면 어떤 과정을 거쳐야하는지 아래 **Page fault trap 파트에서 자세히 살펴보자**

<br/>

## Page fault trap

Page fault trap은 **Invalid bit일 때 처리 과정을 설명한다**

![IMG_3304](https://github.com/user-attachments/assets/fcfc1a07-d606-4fd8-9067-9523170d0549)

<br/>

1. 운영체제는 PCB 내 다른 테이블을 참조하여 다음을 결정한다

- 주소 자체가 잘못되었거나 권한 위반이면 프로세스 강제 종료(abort) -> page fault가 아님

- 주소는 유효하지만 메모리에 없는거면 **정상적인 Page Fault** → 메모리로 불러오면 됨 

중요한 것은 주소 자체가 잘못되면 그 즉시 끝나고, **주소가 유효하지만 메모리에 없는거면 아래 과정을 거친다**

<br/>

2. 비어 있는 **물리 메모리 프레임을 확보**

3. 디스크에서 해당 페이지를 읽어와 **확보한 프레임에 로딩**

4. 페이지 테이블 등의 데이터 구조를 **업데이트** -> **업데이트를 해야만 valid bit로 바꿀 수 있음**

5. 페이지 테이블의 **valid-invalid 비트를 v로 설정**

6. 페이지 폴트를 일으킨 명령어를 다시 실행 -> **페이지가 메모리에 올라왔으므로 정상적으로 작동**

<br/>

### page falut의 단점은 위 6가지 과정이 너무 오래 걸린다는 것이다

이것을 아래에서 자세히 살펴보자 

<br/>

## Pure paging

**Pure paging** :  페이지 기반 메모리 관리에서 처음에는 어떤 페이지도 미리 메모리에 올리지 않고, **실제로 접근될 때만 페이지를 로딩하는 방식**

Pure Paging은 Demand Paging을 구현하는 가장 단순하고 극단적인 전략이다. 즉 이번 파트에서 demand paging의 page falut 과정을 살피기 위해 가져온 개념이다 

Pure paging은 참조(reference)되기 전까지는 **절대로 swap-in하지 않는다** -> 프로그램을 시작할 때 메모리에 **어떤 페이지도 올라와 있지 않음**

따라서 초기에는 **여러 번의 page fault를 유발**할 수 있어서 **시간적으로 너무 많이 소요됨**

<br/>

## Page Fault 시간 소요 

page fault 비율 p는 0 이상 1 이하의 값을 가짐

- **p = 0**이면 **page fault 없음** (매우 이상적 상황)

- **p = 1**이면 **모든 메모리 접근이 page fault 발생** → 최악의 상황

<br/>

**Effective Access Time (EAT)** : 실제 접근 시간을 의미

![IMG_3305](https://github.com/user-attachments/assets/b9875255-a8af-4680-8c4f-df7204815c4c)

위 공식의 의미는 다음과 같다 

- (1 − p): 폴트가 발생하지 않을 확률 → 이 경우는 그냥 메모리 접근 시간만 소요

- p: 페이지 폴트가 발생할 확률 → 이 경우는 swap in/out + 복구 비용이 듬
  
- 두 경우의 가중 평균

<br/>

## EAT 예시 

다음 상황을 가정하자

- 만약 page fault가 없다면 한 번 접근하는 데 200 nanoseconds(= 200ns) 가 소요됨 

- 만약 page fault가 발생하면 총 8ms(=8,000,000ns)의 시간이 소요됨 (swap in/out + 디스크 I/O + 명령 재시작 포함한 시간)

- page fault는 1000번동안 1번 발생한다고 가정하자 

![IMG_3463](https://github.com/user-attachments/assets/3993ae31-8c12-4cb8-8118-1af75f49ae7d)

<br/>

성능이 10% 이상 느려지지 않도록 하려면?

- 220 > 200 + 7,999,800 × p  

- p < 0.0000025 를 만족해야함 

즉, 약 40만 번 중 1번만 페이지 폴트가 발생해야 성능이 유지됨

<br/>

## 참조의 지역성(locality of reference)

위 예시와 같이 page fault는 많은 시간이 소요되지만, 실제로 사용했을 때 시간이 그렇게 오래 걸리지 않는다

메모리 접근은 실제로 **t 시간동안 국소적으로 발생하여** 초기에 page fault가 많이 발생해도 **성능이 좋다**

이렇게 국소적으로 발생하는 특성을 **참조의 지역성(locality of reference)** 이라고 한다 

<br/>

## Page Replacement (페이지 교체)

**Page Replacement** : page fault가 발생했을 때 사용할 수 있는 **빈 프레임이 없다면** 현재 메모리에 있는 **어떤 페이지 하나를 디스크로 내보내고**, 그 자리에 **새 페이지를 올리는 작업**을 의미한다  

우리의 **목표**는 **page fault를 가능한 한 적게 발생시키는 것**이다

<br/>

## Page Replacement 과정 

1. 디스크에서 요청한 페이지의 위치를 찾는다

2. 빈 프레임이 있으면 그걸 사용하고, 없으면 페이지 교체 알고리즘을 통해 **희생될(victim 이라고 함) 프레임**을 선택

3. 해당 프레임에 요청한 페이지를 불러온다

4. 원래 시도했던 명령을 다시 실행한다 (page fault 복구 완료)

**victim이 될 프레임을 정하는 기준은 가장 최근에 안 썼던 프레임을 선택한다**

![IMG_3307](https://github.com/user-attachments/assets/28584ad8-1fda-48b3-8884-b10e260c8f11)

위 과정을 보면 일반적인 페이지 교체(Page Replacement) 시 I/O 흐름은 다음과 같다 

- 기존 페이지(victim page)를 디스크에 **write (swap out)**

- 필요한 페이지를 디스크에서 **read (swap in)**

이로 인해 **디스크 I/O가 2번 발생한다**

만약 디스크에 존재하는 page를 메모리에 복사하였는데, 이 page가 수정이 된 적이 없다면, disk에 있는 page에서 바뀐게 없기 때문에 **write 과정을 하지 않아도 된다**

**write의 여부는 modified bit로 확인**한다

- modified bit = 0 -> 수정되지 않음

- modified bit = 1 -> 수정됨

<br/>

## victim 선정 방식 

우리의 목표는 **page fault 를 가장 적게 발생시키는 것**이다

알고리즘을 특정 메모리 참조 문자열(reference string)에 대해 실행시켜, 발생하는 페이지 폴트 수를 계산하여 평가한다

앞으로의 모든 예제에서 사용하는 참조 문자열은 '1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5' 를 사용할 것이다

먼저 FIFO 구조부터 알아보자 

<br/>

## victim & FIFO 구조 

![IMG_3308](https://github.com/user-attachments/assets/aee1bf90-15da-45d0-ab5a-88cba7ed9e79)

첫번째 frame = 3 일 때, 초기에 1번 page가 제일 먼저 들어가고 그 다음 2번 page, 3번 page가 들어간다

4번 page가 들어갈 때 현재 frame이 꽉 차 있으므로 FIFO구조로 제일 먼저 들어간 1번 page가 나오는 형식이다 

<br/>

여기서 중요한 점은 **Belady’s Anomaly (벨라디의 모순)** 에 대한 내용이다 

**Belady’s Anomaly (벨라디의 모순)** : frame 늘렸더니 **오히려 page fault가 더 많아지는 현상**

일반적으로 생각해보면 frame의 수가 많아질수록 공간이 많아지니까 page fault가 덜 발생한다고 생각할 수 있지만, 이는 위 예시에서 보는 것처럼 성립하지 않는다 

<br/>

**다른 예시**

![IMG_3309](https://github.com/user-attachments/assets/afb0758e-c5fa-4c3a-9cfa-da0421c7b25f)

<br/>

## Optimal algorithm

**Optimal algorithm** : **가장 이상적인(이론적으로 최적의)** 페이지 교체 알고리즘

![IMG_3310](https://github.com/user-attachments/assets/5115ad2c-a8f9-46de-8a31-b428a169ad35)

**가장 나중에 다시 사용될 페이지를 제거**한다 → 앞으로 접근이 가장 늦게 있는 페이지를 교체 대상으로 삼는 방식

이것은 이상적인, 즉 가장 좋은 경우를 생각하면서 만든 알고리즘으로 실제로 사용할 때 **예측은 할 수 없다**

따라서 이 방법은 알고리즘이 얼마나 효율적으로 작동하는지 **분석하는 방법으로 사용한다**

<br/>

**예시**

![IMG_3311](https://github.com/user-attachments/assets/aa1377a2-0ac5-444a-9eb5-d358e0c1e7a0)

<br/>

## LRU (Least Recently Used) algorithm (중요하다고 언급)

위 optimal algorithm에서 배웠던 것처럼 미래의 참조를 알 수 없다 

그래서 가장 최근에 사용되지 않은 페이지를 제거하는 **LRU 알고리즘**을 사용한다


**LRU 알고리즘** : **가장 최근에 사용되지 않은 페이지를 제거**하는 알고리즘

현실에서는 과거 이력은 추적 가능하므로, 그를 바탕으로 교체하는 LRU가 현실적인 대안이다 

![IMG_3312](https://github.com/user-attachments/assets/7d102ded-bab8-48e9-906d-8d28d0e0e61f)

<br/>

**또 다른 예시**

![IMG_3313](https://github.com/user-attachments/assets/9e202bcb-678c-4372-a9dc-27f660d1e9bd)

<br/>

## LRU (Least Recently Used) algorithm 장단점 

**LRU 장점** : 실제 시스템에서도 page fault를 줄이는 데 **좋은 성능을 보인다**

**LRU 단점** : 실제로 구현하려면 과거 참조 이력을 계속 추적해야 하므로 **구현이 매우 복잡하다**

<br/>

## LRU 구현 방법

**방법 1: Counter Implementation**

각 페이지 엔트리에 **카운터(시계 값)** 를 둬서 최근에 언제 참조됐는지"를 저장해두는 방식이다

**가장 오래된(값이 가장 작은) 카운터**를 가진 페이지를 제거한다 

**단점** : 시계값 비교, 저장, 갱신이 비쌈 (하드웨어 비용 큼)

![IMG_3314](https://github.com/user-attachments/assets/34b0fbc9-2b3f-4208-a2a6-5d76e472c364)

<br/>

**방법 2: Stack Implementation**

페이지 번호들을 **이중 연결 리스트(double linked list)** 로 구성된 **스택(stack)** 으로 유지하는 방식이다

**최근에 사용한 페이지**는 **스택의 위쪽**에 위치

**가장 오래된 페이지**는 **스택의 맨 아래**에 위치 -> **교체 대상이 맨 아래에 온다**

<br/>

**장점** : LRU를 검색하는 **search time이 빠르다**

**단점** : 리스트를 **유지하는 비용이 크다**, 참조 시마다 포인터 갱신, **구현 복잡**

![IMG_3315](https://github.com/user-attachments/assets/40dd3f26-f53f-4d3d-b809-ae3629819176)

<br/>

위 두 가지 방법은 이론적으로 완벽한 LRU지만 너무 복잡하거나 느리고, 하드웨어 구현이 어려워서 **현실 시스템에 적용하기에는 비용이 너무 크다**

이러한 이유로 등장한 것이 **LRU Approximation Algorithms** 이다 

LRU Approximation Algorithm (LRU 근사 알고리즘)은 **Additional-reference-bits algorithm, Second chance algorithm,  Enhanced Second chance algorithm**의 방식으로 나눌 수 있다. 하나씩 살펴보자 

<br/>

## LRU Approximation Algorithms

**LRU Approximation Algorithms** : 진짜 LRU는 아니지만, 진짜 LRU를 구현하기 어려워서 나온 **대체 방법**이다 

LRU Approximation Algorithms **간단하고 빠르면서도 충분히 좋은 성능을 낸다**

<br/>

일반적인 LRU는 **reference bit**로 0 또는 1를 표시하여 참조 여부를 판단하지만, 이렇게 하면 1초 전에 참조된 page와 10분 뒤에 참조된 page가 모두 1로 표시되기 때문에 구분을 할 수 없다 

이것을 극복하기 위해 **LRU Approximation Algorithms**은 여러개의 비트로 시간을 세밀하게 분석하자는 의미에서 **Additional Reference Bits(중요한 개념, 시험 전 복습할 때 한번 더 확인)** 를 사용한다 

![IMG_3317](https://github.com/user-attachments/assets/cc0c68f0-0c6e-4fdc-b3e6-cf97b51b6836)

<br/>

## Second Chance Algorithm (Clock Algorithm)

위에서 배운 Additional Reference Bits도 사실상 여러 비트를 사용하기 때문에 복잡할 수 있어서 비트를 오직 하나만 사용하자고 제안한 방법이 **Second Chance Algorithm (Clock Algorithm)** 이다 

**Second Chance Algorithm (Clock Algorithm) 특징**

- 참조 비트(reference bit) **한 개가 필요하다**

- 클럭 교체 방식 사용하여 모든 페이지를 **원형 큐(circular queue)** 로 구성하고, 시계바늘처럼 **차례로 순환하며 교체 대상(victim)을 찾는다**

<br/>

이 알고리즘의 이름이 second chance인 이유는 말 그대로 **기회를 2번 주기 때문이다**. 아래 과정을 자세히 살펴보자 

1. 만약 검사하는 page의 refernece bit가 **1이라면 0으로 바꾸고** 다름 page를 검사한다

2. 만약 검사하는 page의 reference bit가 0이라면 **해당 bit를 victim으로 선정**한다

<br/>

![IMG_3318](https://github.com/user-attachments/assets/270e967c-cae1-4dac-aeec-f88ce573a66e)

위와 같이 페이지를 검사하는 포인터를 **clock hand**라고 한다 

![IMG_3333](https://github.com/user-attachments/assets/b23fad04-9781-49ac-9c20-9a989bcbaeb4)

<br/>

## Enhanced Second chance algorithm

**Enhanced Second chance algorithm** : 기존 **Second Chance를 확장**하여, reference bit 외에 **modify bit(수정 비트)** 도 사용하는 알고리즘

![image](https://github.com/user-attachments/assets/30daff25-a17a-45ca-b819-728dd995c067)

- 1 class: (0,0) → 참조 안 됨, 수정 안 됨 → **가장 교체하기 좋음**

- 2 class: (0,1) → 참조 안 됨, 수정됨 → 교체 전에 디스크에 기록해야 하므로 비용 큼

- 3 class: (1,0) → 참조됨, 수정 안 됨

- 4 class: (1,1) → 참조됨, 수정됨 → **가장 교체하기 어려움**

**class 1부터 순서대로 확인**해서 **가장 낮은 번호의 비어있지 않은 클래스**에 해당하는 페이지를 교체



