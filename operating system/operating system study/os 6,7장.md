## Race Condition

**Race Condition** : 둘 이상의 프로세스(또는 스레드)가 공유 자원(예: 변수 count)에 동시에 접근하여 조작할 때, 실행 순서에 따라 결과가 달라지는 현상

![System Resources](../../images/operating%20system%20images/race_condition.png)


<br/>

## Data Consistency

데이터를 정확하게 유지하려면, 여러 프로세스가 공유 데이터에 접근할 때 순서를 제어해야한다

이를 위해 동기화(synchronization) 메커니즘 필요하다 

<br/>

## 예시 

만약 Producer과 Consumer가 아래 코드를 동시에 실행했다고 하자

**1. Producer 코드**

```ruby
while (true) {
    /* produce an item and put in nextProduced */
    while (count == BUFFER_SIZE)
        ; // do nothing

    buffer[in] = nextProduced;
    in = (in + 1) % BUFFER_SIZE;
    count++;
}
```

<br/>

**2. Comsumer 코드**

```ruby
while (true) {
    while (count == 0)
        ; // do nothing

    nextConsumed = buffer[out];
    out = (out + 1) % BUFFER_SIZE;
    count--;
}
```

위 코드에서 주목해야할 점은 count++ 과 count--이다. 이 두 코드는 내부적으로 다음과 같이 진행된다 

<br/>

**1. count++**

```ruby
register1 = count
register1 = register1 + 1
count = register1
```

<br/>

**2. count--**

```ruby
register2 = count
register2 = register2 - 1
count = register2
```

만약, count++에서 내부적으로 더한 뒤에 업데이트가 안 된 상황에서 **race condition이 발생한다면**

count--는 업데이트한 값 말고 초기의 count 값에서 빼는 문제가 발생한다

아래는 2번 단계에서 race condition이 발생한 예이다 

![image](https://github.com/user-attachments/assets/b2935286-158f-4199-986a-0b2e96925a8b)

<br/>

## 해결책 

위에서 소개한 race condition을 해결하기 위한 기본 아이디어는

바로 **각 코드를 끝낼 수 있도록 보장하는 것이다** (atomic하게 실행, atomic : 원자, 최소의)

따라서 race condition을 피하려면 아래와 같이 코드를 작성해야 한다

<br/>

![image](https://github.com/user-attachments/assets/3bb3a49f-b106-4b99-891a-4422a41e26fd)

**각 코드 설명**

- Entry section : 임계 영역에 들어가기 위한 준비

- Critical section : 실제 공유 자원 접근 (위험 구간)

- Exit section : 임계 영역에서 나올 때 정리

- Remainder section : 일반 코드 (혼자 사용하는 데이터 등)

여기서 중요한 개념이 바로 **Critical Section**이다 

**Critical Section**이란 공유 데이터를 읽거나 쓰는 코드 구간으로, 한 번에 하나의 프로세스만 실행되어야 하는 부분이다

<br/>

여러 프로세스가 **공유 데이터(Critical Section)** 를 안전하게 사용할 수 있도록 동기화 프로토콜이 갖춰야 할 3가지 핵심 조건을 소개한다.

**1. Mutual Exclusion (상호 배제)** : 한 번에 한 프로세스만 Critical Section 안에 들어갈 수 있어야 함

**2. Progress (진행 보장)** :Critical Section에 아무도 없을 때, 들어가려는 프로세스가 있다면 반드시 누군가는 곧 들어가야 함

**3. Bounded Waiting (유한 대기 보장)** : 한 프로세스가 계속해서 무기한 기다리는 일은 없어야 함

<br/>

쉽게 말해 Mutual Exclusion은 race condition이 발생하지 않도록 보장해주는 것이고, Progress는 모든 프로세스가 서로 피하는 상황을 막는 것이다 

<br/>

## Peterson’s Algorithm

**Peterson’s Algorithm**: 두 개의 프로세스가 Critical Section(공유 자원 영역)을 사용할 때 동시에 들어가지 않도록 설계된 알고리즘 

Peterson’s Algorithm(피어슨 알고리즘)은 두 개의 프로세스를 기준으로 설계했고 그 이상은 다음 파트에 배울 semaphores 를 이용함 

![image](https://github.com/user-attachments/assets/b1942d32-0843-41a3-a52b-2f51de558b22)

<br/>

위 코드를 상황을 보자면, 하나의 공유 자원(전역 변수)를 pi라는 process와 pj라는 process가 동시에 사용하는 상황이고, 맨 위에 turn 값은 초기값인 0으로 설정되어 있다

또한, Boolean flag[2]는 pi와 pj의 현재 상태가 false로 초기화 되었다는 것인데 이것은 이후에 설명하도록 하겠다. 그럼 아래 과정을 살펴보자 

먼저 pi가 해당 전역 변수를 사용하고 싶으면, 첫 코드인 flag[i] = True로 하고 turn = j를 시행하고 

그 후, pj가 요청을 하여 변수만 다른 동일한 코드를 시행하는데

각각의 의미는 다음과 같다 (pi 기준으로 설명)

- flag[i] = True : pi process가 전역 변수를 사용하고 싶다는 의미 

- turn = j : j에게 양보하겠다는 의미

미리 설명하자면, turn = j 가 될 경우 , 해당 while문은 flag의 매개변수가 서로 반대로 되어 있기 때문에 먼저 false가 되어 양보권을 주는 것이다 (pi process는 flag[j]로 되어 있음)

또한, flag 값이 true가 되어야 서로의 코드가 실행이 되므로 이것은 전역 변수를 사용하겠다고 해석함 (그래서 초기값으로 false 설정)

<br/>

현재 상황을 보자면, pi가 들어오고 그 다음 pj가 들어왔으므로 시행 순서는 다음과 같다 

1. flag[i] = True

2. turn = j

3. flag[j] = TRUE

4. turn = i

현재 turn 값은 i이고 이것은 pj 가 pi에게 양보하겠다는 의미로 해석할 수 있다. 

그 이유는 pi의 turn 값이 i라면, pi의 while이 false가 되어 while 문이 종료되어 critical section에 도달할 수 있기 때문이다 

<br/>

이렇게 pi의 critical section이 끝나면, flag[i] = false로 만들게 되는데 

이때, pj의 while 문이 탈출하게 된다 

pj의 while이 끝나면 다시 flag[j] = false가 되어 초기 상태로 돌아온다 -> 이후 이것을 계속 반복 

<br/>

직관적인 예로 보자면 count 라는 전역 변수에 서로 번갈아가며 pi는 +1를 하고 pj는 -1를 하는 상황을 생각해보자 

pi가 실행이 끝나면 pj가 실행이 되고, 또 다시 pi가 연산이 필요하다고 판단되면 다시 이 과정을 반복하는 것이다 

<br/>

하지만 Peterson’s Algorithm은 Busy Waiting(CPU 낭비)과 구현의 어려움이 단점이 존재한다 

<br/>

## 현대의 다중 CPU 시스템

다음은 Peterson’s Algorithm을 대신하여 사용하는 알고리즘인 Test-and-Set과 Swap에 대해 설명하도록 하겠다

<br/>

## TestAndSet()

운영체제에서 여러 작업이 공유 자원에 동시에 접근하지 않도록 하기 위해, TestAndSet이라는 원자적(atomic) 연산을 사용할 수 있다 

TestAndSet()은 아래와 같이 사용한다 

```ruby
## TestAndSet 함수 
boolean TestAndSet (boolean *target) {   -> *target자리에 lock이 들어옴
    boolean rv = *target;      
    *target = TRUE;
    return rv;                           -> lock의 현재 상태를 그대로 반환 
}

## 전체적인 흐름
do {
    while (TestAndSet(&lock)) ;   // lock이 TRUE면 계속 대기
    // critical section
    lock = FALSE;                 // lock 해제
    // remainder section
} while (1);
```

우선 위 코드에서 매개변수로 받은 *target에서 target은 메모리 주소이고 *를 붙여서 해당 값을 불러오는 일반적인 포인터 사용이다 

전체적인 흐름을 설명하는 두 번째 코드를 보면, 일반적으로 **모든 process는 lock 변수의 초기값이 true이다**

lock이 true라는 것은 while문이 계속 실행된다는 의미이고, 즉, **lock = false가 되어야 while이 종료되어** critical section으로 진입할 수 있다 

- lock = true -> 진입 불가

- lock = false -> 진입 가능

<br/>

다시 TestAndSet 함수를 보면 *target에는 lock 자리가 들어가고 boolean rv = *target; 코드를 통해 rv에 할당하여 이것을 그대로 내보낸다 

만약 lock이 False라면, TestAndSet 함수는 입력값을 그대로 내보내기 때문에 false를 반환하여 while이 종료가 되고, 

TestAndSet 함수의 두번째 코드인 *target = TRUE에 의해 lock값이 true가 되어, while문을 탈출하여 임무를 완료한 process는 자동으로 다시 while문 탈출할 수 없게 만든다

<br/>

여기서 중요한 것은 **lock이 전역 변수로 설정되어야 한다는 것이다**

전체적인 흐름은 process들이 선착순으로 도착하여 전역 변수인 lock을 확인하고 critical section에 들어갈 수 있는지 확인한다 

<br/>

lock = false(열림)-> p1(lock = true p1은 실행 후 다시 닫힘) -> critical section(실행) -> lock = false(열림) -> p2(lock = true p2는 살향 후 다시 닫힘) -> ...

<br/>

만약 TestAndSet이 atomic하지 않는다면, target을 false라고 하기 전에 context switch가 발생할 수 있다 -> Mutual Exclusion 위배 

현재는 instruction 이기 때문에 atomic 보장 

여기서 instruction이란 CPU가 수행할 수 있는 가장 기본적이고 작은 작업을 의미

<br/>

## Swap

운영체제에서 여러 작업이 공유 자원에 동시에 접근하지 않도록 하기 위한 또 다른 방법인 swap에 대해 알아보자 

아래의 swap의 예시이다 

```ruby
 void swap (boolean *a, boolean *b)
 {
 boolean temp = *a;
 *a = *b;
 *b = temp:
 }
```

위 코드는 a와 b의 값을 바꿔준다는 의미이다 

그럼 위 swap을 활용한 아래 예시를 보자 

![스크린샷 2025-04-20 191418](https://github.com/user-attachments/assets/d72de0f8-f351-4888-89cf-7ddaf2f9b067)

왼쪽이 process 1 , 오른쪽이 process 2, lock의 초기값 = false 라고 하자 

위 코드를 보면 먼저 실행되는 process 1의 key 값은 True이고, 아래 while문이 실행이 되고, swap 함수를 통해 lock값과 key값이 전환이 된다 

- lock : true로 전환

- key : false로 전환

key값이 false가 되면 while문이 탈출하게 되고, **critical section에 진입할 수 있다**

또한, 마지막에 lock = false가 초기 상태를 만들어 놓고 다음 process가 와서 똑같이 시행하는 방식이다

이 상황에서 process 2도 동시에 실행될 수 있지 않을까라는 생각을 할 수 있는데 

Swap() 함수는 atomic instruction으로 구현이 돼서, 두 process가 동시에 진입하려고 해도 절대 중간에 나눠서 실행되지 않기 때문에 안전하다 

<br/>

process 1이 종료가 되면 이후 process 2도 같은 방식으로 흘러간다 

<br/>

## Waiting Array

우리가 배운 TestAndSet()과 Swap() 방식을 이론적으로 설명해서 process 1 다음에 process 2가 온다고 가정했다

하지만, TestAndSet()과 Swap()은 대기 순서를 기억하지 않기 때문에 실제로 이것을 사용했을 때

process가 오는 순서대로 반드시 실행한다고 보장하지 않아서 **Bounded Waiting (유한 대기)를 보장하지 못한다**

<br/>

예를 들어 process 1이 끝나고 lock = FALSE가 되자마자, OS가 어떤 프로세스를 먼저 스케줄할지는 알 수 없다 

즉, process 1이 remainder 끝내고 다시 빨리 돌아오면 또 이길 수 있어서 process 2가 먼저 올 거라는 보장이 없다 

따라서 Waiting Array는 방식을 도입하여 누가 먼저 기다렸는지 기억하는 구조가 필요하다는 것이다 (이런 개념도 있다고만 설명, 깊게 공부 x 알고만 있기)

<br/>

## semaphore

semaphore(세마포어)는 **정수형 변수 S**이며, 공유 자원의 접근을 제어하는 역할을 한다 

이는 두 가지 연산으로 조작이 된다

- wait(S) → 자원 사용 전 호출 (P()로도 불림)

- signal(S) → 자원 사용 후 해제 (V()로도 불림)

이 연산들은 반드시 **원자적(atomic)** 이어야 한다. 즉, 다른 process가 중간에 끼어들 수 없어야 한다 

<br/>

또한 semaphore는 두 가지 종류도 구성되어 있다 

- Counting Semaphore : 0 이상 정수, 한 번에 여러 개 자원을 허용

- Binary Semaphore (Mutex) : 0 또는 1만 사용, Critical Section 상호배제 보장

<br/>

Counting Semaphore은 한번에 최대 n개를 진입시킬 수 있다 하나씩 critical section에 진입하여 처리하는 구조이다 

즉, Counting Semaphore은 최대 n개의의 process가 자신만의 **개별적인 critical section을 가져서 처리하게 된다** (실제로 많이 사용됨)

<br/>

오해하지 말아야 할 것이 개별적인 critical section을 가지더라도 해당 구역에는 반드시 하나의 process만 처리할 수 있다는 것이다 

다음으로 Binary Semaphore는 상호 배제(Mutual Exclusion), 임계 구역 보호를 목적으로 사용한다 

이해를 돕기 위해 아래 예시를 통해 설명하도록 하겠다 

```ruby
typedef struct {              // 세마포어 구조 선언
    int value;                // 남은 자원 수
    struct process *list;    // 대기 중인 프로세스 리스트
} semaphore; 


wait(semaphore *S) {
    S->value--;                      // 자원 하나 차감
    if (S->value < 0) {              // 만약 차감 결과가 < 0 → 해당 process는 진입 불가 -> list에 보류 
        add this process to S->list; 
        block();                     // 이 프로세스를 block 상태로 전환 -> 즉 waiting 상태가 되어 CPU 반납 + OS가 다음 프로세스 실행한다 
    }
}

signal(semaphore *S) {
    S->value++;                       // 자원 하나 반환
    if (S->value <= 0) {              // value <= 0인 경우 -> list에서 못 들어간 가장 최근의 process 을 진입시킴 
        remove a process p from S->list;
        wakeup(p);                    // 해당 프로세스를 Ready Queue로 복귀시킴
    }
}
```

위 구조를 보면 counting semaphore를 이용하여 n=3 인 상황을 생각해보자 (즉, 처리할 process가 3개인 상황)

typedef struct 함수의 현재 value 값은 3 이고(value는 처리할 proess의 수이다) 만약 첫 번째 process가 진입한다면, wait(semaphore *S) 문에서 value가 1이 차감된다. 

<br/>

이후 process 2와 process 3도 진입에 성공한다 (주의할 점은 처리하는 것은 Critical Section에서 한 process씩 처리한다)

만약 새로운 process 4가 진입하려고 한다면, wait 문의 if에 걸릴 것이다 

이렇게 되면 process 4는 list에 넣어두고, process 3이 signal 문을 통해 process 4 list에서 삭제하고 (즉, 대기열에서 삭제하고) 이 값을 실행을 시킨다

또한, semaphore를 사용하면, bounded waitng이 어느정도 보장이 된다 (100프로는 아님)

<br/>

일반적으로 bounded waiting (유한 대기)는 cpu의 스케줄러의 권한이 압도적이기 때문에 대부분 경우 이것을 보장하지 못함 

<br/>

## 상황적 효율성 

semaphore에는 두 가지 방식이 존재한다 

- Spinlock 기반 세마포어 (busy waiting)

- Blocking 기반 세마포어 (잠재움)

<br/>

만약 어떤 함수 내부에서 길게 기다릴 때는 busy looping이 없이 block(즉, waiting으로 전환하는 것이) 효율적이지만, 짧게 기다리는 경우 오버헤드 때문에 그냥 busy looping을 하는게 더 좋다

busy looping이 없이 block을 한다면, 다음과 같은 오버헤드가 발생한다 

- 레지스터 저장/복원

- 캐시 무효화

- 메모리 접근 비용 증가

즉, 기다리는 시간이 길다면 block이 효율적이지만, 짧게 기다리는 것이라면 오히려 오버헤드가 기다리는 시간을 압도해버릴 수 있다 

<br/>

## Posix 문법 

이번 파트는 간단한 문법 설명이다. 아래 4가지에 대한 문법을 소개하겠다

- Creating a mutex

- Locking a mutex

- Unlocking a mutex

- Destroying a mutex

```ruby
int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr)
// mutex가 참조하는 뮤텍스를 attr이 지정한 속성으로 초기화 한다, attr이 NULL이면, 기본 뮤텍스 속성이 사용

int pthread_mutex_lock(pthread_mutex_t *mutex);
//뮤텍스를 잠금, 만약 이미 잠겨 있다면, 호출한 스레드는 뮤텍스가 사용 가능해질 때까지 block

int pthread_mutex_unlock(pthread_mutex_t *mutex);
// 뮤텍스를 해제, 이 함수는 뮤텍스의 소유자가 현재 스레드인지 확인하고, 맞는 경우에만 뮤텍스를 초기 상태로 재설정함

int pthread_mutex_destroy(pthread_mutex_t *mutex);
// mutex가 참조하는 뮤텍스 객체를 삭제
```

위에서 첫번째 코드를 생성할 때, 전역 변수 a의 critical section과 전역 변수 b의 critical section은 다르기 때문에 

init 생성을 두 번 해줘야 한다 

<br/>

## posix semaphore 구조 

![image](https://github.com/user-attachments/assets/3c510a25-7d6c-4476-b5de-e23c72e04110)

- sem_t sem; : sem은 세마포어 객체, 타입은 sem_t이고, 내부적으로는 정수값을 사용하여 자원 수를 표현

- sem_init(&sem, 0, 1) : &sem: -> 주소, 두번째 인자 공유 여부 결정 0: 0이면 프로세스 내부의 스레드들끼리 공유, 1이면 여러 프로세스 간 공유, 세번째 인자는 Binary Semaphore 초기값 (1 or 0)

- sem_wait(&sem); : 세마포어 값을 1 감소시킴

- sem_post(&sem); : 세마포어 값을 1 증가시킴 































































