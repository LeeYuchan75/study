## Preemptive & Non-Preemptive Scheduling

**CPU 스케줄러 복습**

CPU 스케줄러 : 메모리에 존재하는 실행 준비 상태의 프로세스 중 하나를 선택하여 CPU를 할당하는 기능 담당

<br/>

이때 Preemptive는 CPU가 더 높은 우선 순위가 있다고 판단한 process로 교체할 수 있지만, 

Non-Preemptive는 CPU가 처음 우선 순위가 높은 process를 올려다 놓으면, 이 process가 끝날 때까지 건들 수 없다. 

즉, Non-Preemptive는 **process가 끝날 때까지 반드시 기다려야함**

<br/>

## 개념 정리 

**Nonpreemptive (비선점형)** : 프로세스가 스스로 CPU를 반납할 때만 다른 프로세스가 CPU를 얻을 수 있음 (시간 지연 문제 발생)

**CPU 반환 조건** : waiting 상태로 전환됨 (예: I/O, 동기화), 또는 프로세스 종료

I/O(예: 디스크 읽기, 네트워크 요청)를 요청할 때, waiting(대기) 상태가 되는 이유는 **I/O의 작업이 CPU의 작업 속도에 비해 상대적으로 매우 느리기 때문이다**

그래서 CPU가 이 작업을 waiting상태로 걸어놓고 다른 작업을 한 뒤, I/O 작업이 끝나면 다시 가져오고 식으로 사용 -> 효율성 증가 

<br/>

**Preemptive (선점형)** : 비선점형의 모든 조건 + 추가 조건 (그래서 구현이 어려움)

추가조건은 아래와 같다

- **ready 상태여도 cpu를 가져올 수 있음**

- **Timer interrupts** : 특정 시간 할당량 초과 시 CPU 회수 (대표적인 Preemptive)

<br/>

여기서 주의할 점은, ready 상태는 process가 일이 다 종료되고, 다음 process로 넘긴다는 것이 아니라 언제든 cpu만 받으면 다시 작업을 할 수 있다는 상태이다. 

즉, Non-preemptive 관점에서 보면, Terminated 상태가 되어야 현재 process가 완전히 끝났다고 할 수 있다. 

<br/>

**프로세스 상태 복습**

- New : 생성됨 (아직 준비 안 됨)

- Ready : CPU만 받으면 바로 실행 가능함

- Running : 실제로 CPU에서 실행 중

- Blocked : I/O 같은 이벤트 기다리는 중

- Terminated : 모든 작업 완료 → 끝남

<br/>

## 예시 

**Non-preemptive scheduling**

1. 프로세스 A: 실행 중 (Running)

2. 프로세스 B: I/O 완료로 Ready 상태 전환됨

3. **A가 끝나지 않았기 때문에 B는 Ready 큐에서 기다리기만 함**

4. A가 종료되거나 Blocked 되어야 → B가 CPU를 받을 수 있음

<br/>

반면, Preemptive sheduling 이라면,

B가 Ready로 돌아오는 순간, OS는 스케줄러를 호출해서 A를 중단하고 → B에게 CPU를 넘길 수 있음 

<br/>

## 필기 내용 정리 

![System Resources](../../images/operating%20system%20images/preemption필기내용.png)

## Preemptive Kernel 관점

위에서 말한 preemption은 운영체제가 강제로 중단하고 다른 태스크로 교체하는 것을 말함 

Preemptive Kernel 관점에서 보면, ISR (인터럽트 핸들러) 안에서는 일반적으로 preemption이 발생하지 않음(즉, 강제로 중단할 수 없음) -> ISR은 짧고 빠르게 실행되어야 하며, 도중에 중단되면 복잡한 race condition이 생길 수 있기 때문

System call에서는 preemption이 가능함(강제로 중단할 수 있음) -> (ex: 시스템 콜이 오래 걸리는 경우, 타이머 인터럽트 발생 → 스케줄링 발생 → context switch)

<br/>

## Non-Preemptive Kernel 관점

이것은 애초에 실행중인 process를 건들 수 없으므로 

ISR 중에도 선점이 없고, system call 도중에도 선점이 없다

<br/>

## 추가적으로 

실시간 시스템(real-time computing)에서는 반응 시간 보장이 매우 중요합니다.

Non-preemptive kernel은 system call이 길어지면 다른 프로세스가 응답 지연됨.

따라서 실시간 성능이 떨어짐 → 실시간 시스템에는 Preemptive kernel이 적합.

<br/>

## CPU 스케줄링 평가 기준

**분류 기준: 시스템 vs. 개별 프로세스 관점**

아래와 같이 시스템 전체 관점과 개별 프로세스 관점으로 정리함 

<br/>

## 시스템 전체 관점 (System-wide)

**1. CPU utilization**

**CPU가 얼마나 바쁘게 일했는가**

목표: CPU가 가능한 한 쉬지 않고 일하게 하는 것

수치로 보면: 사용 시간 / 전체 시간 (예: 90% 이상이 이상적) -> 높을수록 좋음

<br/>

**2. Throughput**

**단위 시간당 완료된 프로세스 수**

예: 초당 5개 프로세스 완료 → throughput = 5

클수록 좋음 (작업 처리 효율성 ↑)

<br/>

## 개별 프로세스 관점

**1. Turnaround time**

**제출 ~ 완료까지의 시간**

총 소요 시간 = 완료 시간 - 제출 시간

예: 사용자가 1시에 제출 → 1시 5분 완료 → Turnaround = 5분

<br/>

**2. Waiting time**

**Ready 큐에서 대기한 시간** (CPU 못 받고 대기한 시간의 총합)

총 실행시간: 10분

I/O 대기 제외 대기시간: 6분 → Waiting time = 6분

<br/>

**3. Response time**

**처음 반응이 나오기까지 걸린 시간**

예: 요청 입력 → 첫 결과 화면 출력까지 걸린 시간 (전체 완료 시간과는 다름)

<br/>

![System Resources](../../images/operating%20system%20images/time_criteria.png)

<br/>

## 예시 1 

![System Resources](../../images/operating%20system%20images/turnaround_예시.png)


**Turnaround Time = 프로세스가 제출된 시점부터 완료될 때까지 걸린 전체 시간**

여기에는 다음이 모두 포함됨

- 메모리에 들어가기까지의 대기 시간 (Waiting to get into memory)

- Ready queue에서 기다린 시간 (Waiting in ready queue)

- 실제 실행 시간 (CPU burst)

- I/O 처리 시간 (I/O burst)

위 요소들이 반복될 수도 있음

<br/>

**Waiting Time = 프로세스가 Ready Queue에서 CPU를 기다린 시간의 총합**

즉, Waiting Time은 Turnaround Time의 일부이므로 

**항상 waiting time < Turnaround 이다**

<br/>

## 예시 2 

마지막 문장 오타 of process 1 -> of process 

![System Resources](../../images/operating%20system%20images/tiemaround_예시2.png)

```ruby
## Process 1 

a: Waiting in ready queue (처음 대기)
→ CPU burst (실행)
→ I/O 또는 다른 이유로 다시 대기
b: Waiting in ready queue (두 번째 대기)

## Process 2

Waiting in ready queue (처음 대기)
→ 다른 이유로 또 Ready queue에 들어감 (두 번째 대기)
→ CPU burst (처음 실행)
```

![image](https://github.com/user-attachments/assets/9057ce9e-870c-4dee-aeb6-2c2fdff2c116)

Process 1은 초반에 실행 기회를 빨리 얻었고, (response time = a)

Process 2는 여러 번 기다린 후에야 처음 실행되는 구조(response time = a + b)

즉, Response time 측면에서 Process 1이 훨씬 유리하고,

Process 2는 많이 기다렸다가 실행된다는 점이 핵심 차이

<br/>

## First-Come, First-Served (FCFS) Scheduling

![스크린샷 2025-04-17 140119](https://github.com/user-attachments/assets/9e1b8b11-9e8a-4d2a-bd3c-8ac40231afbc)

FCFS : 먼저 도착한 프로세스부터 실행하는 비선점형 스케줄링 (큐처럼 작동 → 먼저 온 순서대로 CPU를 할당함)

프로세스 도착 순서 : P₁ (24), P₂ (3), P₃ (3)

<br/>

**waiting time**

- P₁: 0 (맨 처음 실행됨)

- P₂: 24 (P₁ 끝나길 기다림)

- P₃: 27 (P₁ + P₂ 끝나길 기다림)

<br/>

**Average Waiting Time** 

평균 대기 시간 : (0 + 24 + 27) / 3 = 17

이 경우 짧은 작업들이 긴 작업 때문에 오랫동안 기다리기 때문에 **매우 비효율적이다**

아래 개선된 FCFS 스케줄링을 보자 

<br/>

![image](https://github.com/user-attachments/assets/4acb5f00-a836-4512-aa4c-87475e405680)

프로세스 도착 순서 : P₂ (3), P₃ (3), P₁ (24)

Waiting Time:

- P₂: 0 (가장 먼저 실행)

- P₃: 3 (P₂ 끝나고 실행)

- P₁: 6 (P₂ + P₃ 끝나고 실행)

<br/>

Average Waiting Time = (6 + 0 + 3) / 3 = 3 이므로 **훨씬 효율적이다**

첫번째 예시 처럼 FCFS는 단순하지만, 긴 프로세스가 앞서면 전체 시스템 성능을 저하시킬 수 있다는 단점이 있다.

<br/>

## SJF (Shortest-Job-First) 스케줄링

SJF 방식은 **다음 CPU burst 시간이 가장 짧은 프로세스에게 CPU를 먼저 할당하는 방식이다**

즉, **SJF는 평균 대기 시간(Average Waiting Time)을 최소화하는 알고리즘**

SJF가 평균 대기 시간을 최소화 하는 이유는 아래와 같다 

![image](https://github.com/user-attachments/assets/146732f9-9b1f-4741-883c-2686a82a1471)

가장 짧은 process로 정렬했을 때 걸리는 평균 시간을 보면 ( (3la + 2lb + lc) / 4 ) 가장 큰 계수인 3이 가장 짧은 소요 시간인 a와 곱해짐 -> 효율적 

SJF 또한 다음과 같은 두가지 방식이 존재한다 

- Non-preemptive: 실행 중인 프로세스를 강제로 중단하지 않음

- Preemptive (SRTF): 더 짧은 작업이 도착하면 현재 프로세스를 선점

<br/>

## SJF & Non-preemptive

프로세스들이 언제 CPU를 사용하고, 얼마나 오래 사용했는지를 시간 순서대로 보여주는 막대 그래프를 Gantt(간트) 차트라고 한다 

![image](https://github.com/user-attachments/assets/c41687e6-d590-46ec-a4cb-46666ff469c9)

P₁은 0에 도착하므로 먼저 실행

P₁이 끝난 시점(7)에 도착해 있는 프로세스들 중 CPU burst시간이 가장 짧은 것을 선택 

**P₃ (1)이 가장 짧으므로 다음 차례에 실행한다**

다음으로 P₂ (4), P₄ (4) 순으로 진행한다 

<br/>

## SJF & preemptive

현재 실행 중인 프로세스보다 **더 짧은 남은 실행 시간을 가진 프로세스가 도착하면 선점함**

![image](https://github.com/user-attachments/assets/96ed8d59-29af-4467-a484-985766017b30)

현재 상황을 보면 P1이 가장 먼저 도착했으므로(도착 시간이 0인 것은 처음부터 여기에 존재했다는 의미) P1이 시행이 되다가 

P2가 도착하면, P1의 **남은 CPU burst(2초 시행했으니 5초 남음)** 와 P2의 CPU burst(4)를 비교한다

비교했을 때, P2가 더 작으므로 P2를 시행 -> **남아 있는 CPU burst를 비교하는게 핵심**

이후 P3 와 P4가 도착했을 때도 마찬가지로 P1과 P2는 수행 후 **남아 있는 시간으로 비교함**

<br/>

또한 2초 지점에서 P2가 2초 수행되고 4초 지점에 P3가 1초 수행 될 때, **P2는 ready queue에 존재하고**

다시 P2가 5초 지점에 수행될 때, **이때 P2의 waiting time은 1초가 된다**

<br/>

## 문제점 

위 두가지 방법의 핵심은 CPU burst를 가장 짧게 소요되는 process를 다음 차례에 시행한다는 것이다 

그런데 위 예시에서는 우리가 process의 CPU burst를 정한 것이지 실제로는 각 process가 얼마만큼의 CPU burst가 걸릴 지 모른다(미래를 예측할 수 없음)  

따라서 컴퓨터는 정확하게 판단할 수 없기에 다음과 같은 예측 방법을 사용한다. 

<br/>

## Exponential Averaging (지수 평균법)

지수 평균법의 해당 process가 **가장 최근을 기준으로 소요 시간이 얼마였는가를 계산한 것이다**

**여기서 핵심은 최근이다**, 대학에서 우리의 고등학교 성적을 볼 때, 고3 성적이 제일 중요한 이유와 비슷하다

![image](https://github.com/user-attachments/assets/bb523b85-fb20-4589-9756-add0edc072ef)

위 4번 정의에서 각각의 의미는 다음과 같다

- tₙ : 이번 실제 CPU burst 시간

- τₙ : 지난 번 예측값

- τₙ₊₁ : 다음 burst 예측값

- α : 가중치 계수 (0 ≤ α ≤ 1)

<br/>

위 공식을 점화식으로 풀면

**τₙ₊₁ = αtₙ + (1-α)αtₙ₋₁ + (1-α)²αtₙ₋₂ + ... + (1-α)ⁿ⁺¹t₀** 이렇게 흘러간다 

여기서 중요한 것은 **뒤로 갈수록 가중치가 제곱이 된다는 것이다**

a의 범위는 0< a < 1 이기 때문에 곱할 수록 작아져서, 결국 가장 최근 CPU burst 값에 가장 큰 가중치를 준다 

<br/>

따라서 지수 평균법은 SJF 스케줄링에서 CPU burst를 예측하기 위한 현실적인 방법이며, α를 통해 과거와 현재 정보를 조절하여 예측의 민감도를 조절한다 

<br/>

## 예시 

아래 검은색 선은 실제 CPU burst 시간이고, 파란색 선은 예측 값이다 

![image](https://github.com/user-attachments/assets/9f5db913-df4f-479c-81d9-10a8d01fc902)

<br/>

과정은 다음과 같다 

**1. 초기 예측값**

임의로 𝜏0를 10으로 설정하고 가중치는 1/2로 설정 

공식 : 𝜏(n+1) = 1/2 x tn + 1/2 x 𝜏(n)

<br/>

**2. 실제 과정**

![image](https://github.com/user-attachments/assets/7a94c95c-6c1e-4008-8055-8753eb962a4b)

<br/>

## 정리 + 문제점

앞에서 계속 우선 순위가 가장 높은 process에게 CPU를 먼저 할당하는 스케줄링 방식 **Priority Scheduling이라고 한다**

Priority Scheduling은 두 가지 방식이 있다 

<br/>

- Preemptive : 높은 우선순위 프로세스가 도착하면 현재 실행 중인 프로세스를 선점함

- Non-preemptive : 현재 실행 중인 프로세스가 끝나야 교체됨 (선점 없음)

<br/>

SJF는 일종의 Priority Scheduling이다 (단, 여기서 우선순위는 CPU burst 길이에 기반하여 자동 결정됨)

<br/>

**Priority Scheduling의 문제점은 다음과 같다**

Starvation (기아) : 우선순위가 낮은 프로세스가 계속 밀려서 실행 기회를 얻지 못하는 현상

Starvation 해결 방법 : **Aging 기법** -> 대기 시간이 길어질수록 우선순위를 점점 올려주는 기법

<br/>

**추가 설명**

- Static Priority : 우선순위는 고정됨. 한 번 정해지면 변하지 않음. 실시간 시스템에서 자주 사용

- Dynamic Priority : 우선순위가 실행 중에 변할 수 있음 (예: Aging, I/O 특성 등 반영). 대기시간 보정 필요 시스템에서 자주 사용






































































































































































