## Counter-Based Algorithm

**Counter-Based Algorithms** : 페이지마다 **사용 횟수를 추적**하는 알고리즘 

Counter-Based Algorithm에는 **LFU (Least Frequently Used) Algorithm**과 **MFU (Most Frequently Used) Algorithm**이 존재한다 

<br/>

- **LFU 알고리즘** : **참조 횟수가 가장 적은** 페이지를 교체함

- **MFU 알고리즘** : **참조 횟수가 가장 많은** 페이지를 교체함

<br/>

## 예시 

다음과 같이 참조된 비트가 존재한다고 가정하자 

- A = 10000000

- B = 00111111

이때 LRU, LFU, MFU 알고리즘에 따라 victim을 어떻게 선정하는지 알아보자 

- **LRU** : 이진수 값으로 A > B 이므로 **B가 victim**

- **LFU** : 참조된 페이지의 수가 A가 더 적으므로 **A가 victim**

- **MFU** : 참조된 페이지의 수가 B가 더 크므로 **B가 victim**

<br/>

## Thrashing (스래싱)

**Thrashing (스래싱)** : 프로세스가 계속해서 페이지를 메모리에 넣었다 뺐다 반복하고 있는 상태

**Thrashing (스래싱) 원인**

1. **메모리가 부족 -> 근본적 원인**

2. 어떤 프로세스에 할당된 페이지 수가 충분하지 않게됨 -> **페이지 폴트(page fault)** 가 자주 발생

3. 이로 인해 Disk/IO 자주 발생

4. CPU는 료율적인 작업을 하지 못하고, 단순히 Disk/IO만 불러오는 작업만 하게 됨

**즉, 메모리가 부족하여 cpu의 성능이 떨어지는 상태를 말한다**

<br/>

## Thrashing (스래싱) 이해를 위한 자료 

![IMG_3335](https://github.com/user-attachments/assets/e6f39581-17b4-499d-ab0d-4b72c4d4d68d)

<br/>

## Thrashing (스래싱) 해결 방법 

스레싱(thrashing)을 방지하려면, 프로세스에 **필요한 만큼의 프레임을 제공**해야 한다

이때 필요한 프레임 수를 어떻게 추정할 수 있을까 ? 바로 **Locality model 모델을 사용하는 것**이다

아래 예시는 쉽게 말해 page에 할당된 memory로 판단하는 것이 아니라, **실제 사용된 page 메모리로 계산을 해야** 정확하게 판단할 수 있다는 것이다

<br/>

**중요 개념**

- **locality** : 특정 시간에 접근되는 **메모리 주소(= 페이지)들의 집합** (ex: Page A가 20MB를 요구하더라도, 실제로는 그 중 3~4MB 정도만 접근)

- **Δ (델타), 또는 time window** : 페이지를 검사하는 특정 시간

![IMG_3342](https://github.com/user-attachments/assets/e30df3be-e75c-42b2-8162-24f39ef4af7a)

위에서 구한 것처럼 **locality의 합 > total memory size 여야 Thrashing이 발생하지 않는다**

그럼 **Locality model** 중에서 **Working Set Model**에 대해 알아보자

<br/>

## Working Set Model (시험 출제 예고, p.35 시험 문제 참고)

**핵심 개념** (아래 예시를 보면서 이해)

- **Δ(델타) 또는 워킹셋 윈도우(working-set window) 또는 window size** : 고정된 수의 페이지 참조 횟수를 의미함 (ex: Δ = 10,000 이면, 최근 참조한 page를 10,000개를 보고 판단하는 것 -> **locality 성질**)

- **WSSᵢ (working set of Process Pᵢ)** : 프로세스 Pᵢ의 워킹셋(WSSᵢ)은, **가장 최근 Δ 동안 참조된 페이지들의 총 수**를 의미

-  **D = ∑WSSᵢ** : D는 모든 프로세스의 WSS를 합한 값으로, 총 프레임 수요량

-  **m** : 물리 메모리 크기

<br/>

**성질**

-  Δ가 너무 작으면, 지역성 전체를 포함하지 못할 수 있다

-  Δ가 너무 크면, 여러 지역성을 포함하게 된다

- Δ가 무한대면, 프로그램 전체를 포함하게 된다

<br/>

**Working set model이 Thrashing을 판단하는 방법**

![image](https://github.com/user-attachments/assets/6de65bf8-0136-445f-90f7-637eba3936a6)

Working set model은 **D가 m(물리 메모리 크기)보다 크면** 스레싱 발생한다 

D > m일 경우 **일반적인 해결 방법**은 **프로세스 하나를 중단(suspend)하는 것**이다

<br/>

## 예시

아래 예시는 위에서 설명한 3~4 메모리만 사용한다는 예시와 다르게 프로세스 전체를 사용하되, 시간을 정해서 보는 것

즉, 프로세스 전체 메모리를 보지 않고, 전체 페이지 집합 중에서 최근 시간(Δ) 동안 참조된 것만 보는 것 

![IMG_3343](https://github.com/user-attachments/assets/ad3ea2ab-b99c-469d-a0bd-31919c635abf)

<br/>

## Allocating Kernel Memory (커널 메모리 할당)

운영체제의 핵심인 커널은 일반 사용자 프로그램과는 다른 방식으로 메모리를 관리해야 하므로, 별도의 메모리 관리 방식이 필요하다 (커널도 프로그램이기 때문에 메모리가 필요함)

커널은 미리 확보해 둔 **자유 메모리 풀(free-memory pool)** 에서 필요한 만큼을 가져다 쓴다. 이는 빠른 처리를 위해 일반적이다

- 커널은 다양한 크기의 구조체를 위해 메모리를 요청한다

- 일부 커널 메모리는 물리적으로 연속된 공간이어야 한다.

커널 메모리를 효과적으로 관리하기 위해 사용하는 대표적인 기법 중 우리가 공부할 것은 **Buddy System**과 **Slab Allocator**이다 

간단하게 정리하면 

- **Buddy System**  : kernel에서 **연속적인 memory 공간이 필요할 때** 사용, **page 개수로 요청함**

- **Slab Allocator** : kernel 내부에서 **object 할당 시** 사용, (ex : 세마포어, PCB를 기록할 때 메모리 공간이 필요함)

<br/>

## Buddy system 

**Buddy System (버디 시스템)** 은 물리적으로 **연속된 페이지로 구성된 고정 크기 세그먼트에서 메모리를 할당**한다

**메모리는 2의 거듭제곱 크기 단위**로 할당된다

- 요청은 2의 제곱 크기 단위로 만족된다 (ex: 100KB를 요청하면 128KB로 올려서 할당된다)

- 요청 크기는 그보다 큰 가장 가까운 2의 제곱수로 올려진다

- 요청보다 큰 블록만 있을 경우, 현재 블록을 다음 작은 2의 제곱 단위로 나눠 두 개의 '버디'로 만든다

- 적절한 크기의 블록이 나올 때까지 계속 분할된다

<br/>

### 버디 시스템의 핵심 개념인 두 가지 동작

1. **Splitting (분할)** → 큰 블록을 두 개의 작은 블록(버디)로 나누는 과정

2. **Coalescing (병합)** → 할당 해제된 버디 블록이 만나면 더 큰 블록으로 병합하는 과정

<br/>

### Buddy system 예시

총 512 pages의 할당 되지 않은 메모리가 존재할 때 

<br/>

### Splitting (분할) 과정 

- **allocate(253)** : 253개의 page를 요청하면 253은 2의 거듭제곱이 아니므로 다음 큰 크기인 256이 필요하다

- 512 블록을 256 + 256 버디로 나눈 후, 256을 할당

- **allocate(124)** : 이후 또 다시 124개의 page를 요청하면 올림해서 128 크기 필요하다

- 256을 다시 128 + 128로 나눠서 할당

<br/>

### Coalescing (병합) 과정 

위 Splitting 과정에서 A, B, C 등의 블록이 존재하고, C가 128크기로 할당되었을 때, C가 page를 다 사용하여 반환하는 경우를 생각해보자 

- **release(C, 128)** : C가 해제됨 → 이때 C의 버디 블록이 비어 있다면 병합 가능

- C의 **버디**란 할당되지 않은 page에서 C에게 page를 주기 위해 256을 2개로 쪼개서 하나를 C에게 할당하였을 때, **남는** 128 page를 말한다

- 왜 C와 C의 버디랑 결합해야 하냐면 C가 128 page를 요청했을 때, 256 page에서 쪼개면, 256 page는 연속적인 페이지 이기 때문에 **C와 C의 버디 주소가 이어져있다** 병합 조건을 보면 **주소 상 인접해야 병합이 가능하기 때문에** C와 C의 버디가 서로 결합하는 것이다 

- C와 D가 같은 크기로 할당했더라도, C와 D의 주소가 다르기 때문에 C와 D의 버디를 **병합할 수 없다**

<br/>

여기서 병합할 때 다음과 같은 조건이 존재한다 

- 같은 크기 (ex: 128 + 128 (0), 128 + 256 (x))

- 주소 상 인접 : 인접해야 병합 가능 

- 둘 다 free 상태일 경우 병합 가능 : 병합할 때는 모두 free 상태이기 때문에 page 내부의 데이터가 유효하지 않게 된다

<br/>

## Slab Allocator

운영체제 커널은 다양한 자료구조(예: 프로세스 제어 블록, 세마포어 등)를 자주 만들고 삭제한다 

이때마다 일반적인 메모리 할당 함수를 쓰면 **느리고 단편화(fragmentation)** 가 발생할 수 있다 (ex: 페이지 하나당 4KB인데 2KB를 지속적으로 요청)

이것을 해결하기 위해 나온 것이 바로 **슬랩 할당자(Slab Allocator)** 이다 

<br/>

### 핵심 개념

- **슬랩(Slab)** = 연속된 메모리 블록으로 하나 이상의 연속된 페이지로 이루어진 덩어리이다 

- 슬랩(Slab)에는 특정한 구조체 하나만 반복해서 저장한다 (ex: 모두 세마포어만 저장하는 슬랩)

- **캐시(Cache)** = 같은 종류 object들을 저장하는 공간 **(하드웨어 cache와 다름)**

- ex: semaphore 캐시 → 세마포어만 저장하는 **슬랩들의 모음**

- **Object (객체)** : 슬랩 안에 들어 있는 구조체 하나의 인스턴스

<br/>

### 전체 구조 

```ruby
Cache
 ├── Slab 1
 │    ├── Object 1
 │    ├── Object 2
 │    └── ...
 ├── Slab 2
 │    ├── Object 1
 │    ├── Object 2
 │    └── ...
 └── ...
```

<br/>

### Slab allocation 핵심 목적 

핵심 목적 : **낭비없이 메모리를 사용하기 위함**

<br/>

### 슬랩의 상태

1. **free 상태**: 아직 쓰지 않은 객체 (초기에는 모두 free)

2. **used 상태**: 이미 사용 중인 객체 (구조체가 저장되면 used로 표기)

<br/>

![IMG_3392](https://github.com/user-attachments/assets/3890e7da-e0ac-4435-9032-99e2a38f88f4)

<br/>

### Slab Allocator 장점 

1. **단편화가 없다**

2. **internal fragmentaion 발생 x** -> 슬랩 안 객체 크기를 딱 맞게 나눴기 때문

3. **빠르게 메모리 요청을 만족시킨다**

<br/>

### 이해를 위한 예시 

만약 일반적으로 malloc(2KB)를 하면 page 하나당 4KB 이기 때문에 2KB가 낭비되고,

이것을 50번 반복하면 100KB가 낭비되는 것이기 때문에 **internal fragmentaion(내부 단편화) 이 심해진다**

하지만 Slab Allocator는 초기에 **미리 만들어 놓고 할당하기 때문에** object를 필요할 때마다 낭비 없이 사용할 수 있다 

<br/>

## p.45,46 필기본 이해하기 











































