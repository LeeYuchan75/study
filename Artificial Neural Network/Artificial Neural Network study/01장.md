### 머신러닝 종류

- **Supervised learning (지도학습)** :정답(레이블)이 붙어 있는 예시 데이터를 가지고 학습

- **Unsupervised learning (비지도학습)** : 정답이 없는 데이터를 보고, 패턴이나 그룹(군집)을 찾아낸는 것

- **Reinforcement learning (강화학습)** : 보상 신호를 받아서, 보상을 최대로 하는 방법을 학습

<br/>

### Supervised learning (지도학습)

- **예시 1** : **MNIST 데이터셋**을 이용한 손글씨 숫자 분류 -> 손글씨 숫자 이미지를 보고 예측하는 것
   - data : 사람이 직접 라벨링한 70,000개의 손글씨 숫자 이미지
 
   - Training set : 처음 60,000개 이미지 → 신경망을 학습시키는 데 사용
 
   - Test set : 마지막 10,000개 이미지 → 학습 중에는 사용하지 않고, 성능 평가에 사용
     
   - Input: 손글씨 이미지

   - label: 숫자 라벨 (0~9)
 
<br/>

MNIST를 이용하여 손글씨 2를 찾는 장면

![System Resources](../../images/Artificial%20Neural%20Network%20images/supervised_learning_예시.png)

<br/>

- **예시2** : **Object recognition (객체 인지)** -> 사진 속에 있는 물체가 무엇인지 맞추는 문제

   - ImageNet 데이터셋 : 수천 개의 카테고리, 수백만 개의 라벨링된 이미지
 
   - 매년 ImageNet 대규모 시각 인식 챌린지도 열림
 
   - 카메라 각도, 조명, 환경 등이 다양함 -> **같은 물체라도 조건이 달라서** 인식이 어렵다
 
   - 딥러닝 기술이 발전하면서 성능이 크게 향상

<br/>

![System Resources](../../images/Artificial%20Neural%20Network%20images/객체인지_예시.png)

<br/>

- **예시3** : **Neural Machine Translation (신경망 기반 기계 번역)**

     - 영어 문장을 입력하면 Encoder가 의미를 벡터로 바꿔줌 → 이 벡터를 Decoder가 다시 다른 언어(스페인어) 문장으로 변환
     
     - 즉, 입력(영어 문장)과 출력(스페인어 문장)을 라벨로 학습하는 구조

<br/>

![System Resources](../../images/Artificial%20Neural%20Network%20images/지도학습_예시3.png)

<br/>

- **예시4** : **Caption generation (캡션 생성)** : 이미지에 맞는 설명(문장)을 자동으로 만들어내는 것
   
    - CNN은 이미지를 이해하고
    
    - RNN은 그 결과를 바탕으로 문장을 만들어냄
 
    - ex: 시장 사진 → "사람들이 야외 시장에서 쇼핑하고 있다."
 
![System Resources](../../images/Artificial%20Neural%20Network%20images/캡션_예시.png)

<br/>

### Supervised learning (지도학습) 문제 정의 

- 지도학습 전 준비 : p개의 예측 변수 x 벡터와 결과 변수 y
   - 회귀 문제 : Y가 수치형(숫자) 값 ex: 가격(만원 단위), 혈압(mmHg), 몸무게(kg)
 
   - 분류 문제 : Y가 유한하고 순서 없는 집합의 값 ex: 생존/사망, 손글씨 숫자(0~9), 조직 샘플의 암 종류

<br/>


### Unsupervised learning (비지도 학습) 발전 과정 

기술이 발달할수록 더 자연스러워짐

![System Resources](../../images/Artificial%20Neural%20Network%20images/비지도학습_발전과정.png)

<br/>


### Unsupervised learning (비지도 학습) 최신 기술 성과

- 왼쪽: 가짜 얼굴 (실제로 존재하지 않는 사람들)

- 오른쪽: 가짜 방/침실 사진

![System Resources](../../images/Artificial%20Neural%20Network%20images/비지도학습_성과.png)

<br/>

### Unsupervised learning (비지도 학습) CycleGAN 모델 성과 

CycleGAN이라는 모델은 말 사진과 얼룩말 사진을 학습해서, 서로 변환이 가능함 

![System Resources](../../images/Artificial%20Neural%20Network%20images/cycle_GAN.png)

<br/>

### Reinforcement learning (강화학습)

- 에이전트(학습하는 주체)는 환경과 상호작용한다

- 각 단계에서
   - 에이전트는 관찰(observation)결과를 받고 이로써 상태(state)를 알 수 있다
 
   - 이후 에이전트가 행동(action)을 선택한다
 
   - 일정 주기로 보상(reward)을 받는다
 
에이전트는 **관찰을 행동으로 바꾸는 규칙(policy)** 을 학습하려고 한다. 이 규칙은 시간이 지남에 따라 **평균 보상을 최대화하는 것이 목표**다

<br/>

### Reinforcement learning (강화학습) 사례 : DeepMind

- DeepMind라는 회사는 신경망을 훈련시켜 여러 가지 Atari 2600 게임을 플레이함
    - Atari 2600에는 약 50개의 게임이 존재
 
- 입력은 게임 화면 자체, 즉 픽셀을 사용하고, 보상은 점수로 제공

- 여기서 중요한 것은 **하나의 동일한 신경망 구조(single network)** 를 모든 게임에 사용했다는 것이다
     - 쉽게 말해서, Atari 2600에 존재하는 벽돌게임을 모델과, 팩맨 게임을 위한 모델을 따로 구분하지 않고 하나의 모델만을 사용
 
     - 실제로, 사람보다 더 우수한 성적을 냈음
       
<br/>

### Statistical Learning (통계적 학습)

- **Statistical Learning (통계적 학습)** : 복잡한 데이터셋을 모델링하고 이해하기 위한 도구들의 집합
 
- Statistical Learning (통계적 학습)과 머신러닝은 **둘 다 지도학습과 비지도학습**을 다룬다는 공통점이 존재
     - **머신러닝 관점** : 맞고/틀리다(정답 예측)이 중요 ex: XGBOOST 
 
     - **통계적 학습 관점** : 상관관계를 찾고 설명하는 것 ex: linear regression, logistic regression

<br/>

### Statistical Learning (통계적 학습) 실생활 예시 

1. 전립선암 위험 요인 찾기 : 환자 데이터(나이, 체중, 호르몬 수치 등)를 분석

2. 이메일 스팸 탐지 → 단어 출현 빈도를 이용하여 텍스트 데이터 분류

3. 유전자 기반 암 분류 → 유전자 발현 정보를 바탕으로 생물학/의학 데이터 분류

4. 위성 이미지 픽셀 분류 → 위성 이미지의 픽셀를 이용하여 영상 데이터 분류

<br/>

### 훈련 데이터를 기반으로 우리가 하고자 하는 목표

- 아직 보지 못한 테스트 데이터(unseen test cases)를 정확히 예측하는 것

- 어떤 입력 변수들이 결과에 영향을 주는지, 그리고 그 방식은 무엇인지 이해하는 것

- 우리의 예측과 추론이 얼마나 좋은지 평가하는 것

<br/>

### 철학적 관점 

- 여러 기법들의 아이디어를 이해하는 것이 중요함
     - 그래야 언제, 어떻게 써야 하는지 알 수 있음

- 더 복잡한 방법을 이해하려면, 먼저 단순한 방법을 이해해야 한다
     - 기초(예: 선형회귀)를 먼저 알아야 고급 기법(예: 딥러닝)도 이해 가능
 
- 단순한 방법이 종종 복잡한 방법만큼 잘 작동한다
     - 로지스틱 회귀가 딥러닝만큼 스팸 분류를 잘할 수도 있음 

<br/>

### neural network (신경망)

- 초창기 신경망 연구(1940~1950년대)는 인간 뇌의 뉴런을 흉내 내서 "컴퓨터가 뇌처럼 생각할 수 있을까?" 하는 모방 목적이 강함

- **기본 아이디어** :  수천(또는 수백만)의 **단순한 처리 단위**들이 모여서 유용한 계산을 수행
  
- 신경망은 원래 뇌에서 영감을 받았지만 현재는 순수하게 수학적·통계적 도구로 보고 있음

- 아래 식을 여러번 반복하여 매우 복잡한 함수를 근사할 수 있음 (뇌의 구조와 동일)

    - 입력(xi)을 받는다

    - 가중치(wi)와 곱해 중요도를 반영한다

    - 편향(b)을 더해 기준점을 조정한다

    - 활성화 함수(g)로 비선형성을 준다

    - 출력(y)을 만든다 

![System Resources](../../images/Artificial%20Neural%20Network%20images/신경망수식.png)

- 신경망 구조 -> 이미지 인식, 언어 번역, 음성 인식, 질병 진단, 로봇 제어 등 여러 분야에서 잘 작동함

<br/>

### Deep Neural Networks (심층신경)

- **신경망(Neural Network, NN)**

    - 은닉층이 0개, 1개, 또는 여러 개여도 모두 신경망이라고 부름 

- **심층신경망(Deep Neural Network, DNN)**

    - 은닉층이 2개 이상인 경우

<br/>

### 머신러닝 vs 딥러닝 

- **머신러닝**

    - **정의** : 데이터로부터 규칙을 학습하는 모든 알고리즘

    - 사람이 직접 특징을 설정
 
    - 회귀, 트리, SVM, NN 등 다양
 
<br/>

- **딥러닝**

    - ML의 하위 집합

    - 모델이 특징을 자동 학습
    
    - 주로 심층신경망(DNN)


