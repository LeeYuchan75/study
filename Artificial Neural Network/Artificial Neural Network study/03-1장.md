### Terminology (용어 정리)

- **output(출력)의 종류**

    - **Machine Learning (머신러닝)**

        - 입력과 출력 쌍을 가지고 학습하는 지도학습 형태
     
            - 비지도 학습과 강화 학습은 output이 존재 x 

    - **Statistical literature (통계적 문헌)**
 
        - {Predictors, Responses} 형태 :  (예측 변수, 반응)
     
        - {Independent variable, Dependent variables} 형태 : (독립변수(입력), 종속변수(출력))
     
    - **Quantitative Output (정량적 출력)**
 
        - 출력값이 **수치**로 나오는 문제
     
        - 어떤 측정값은 다른 것보다 크거나 작다
     
    - **Qualitative Output (정성적 출력)**
 
        - **범주(카테고리)** 로 분류하는 문제
     
        - 특수한 경우로 크기 순서가 존재하는 **순서형 범주형(ordered categorical)** 도 존재
     
            - ex: 티셔츠 사이즈 S, M, L

<br/>

- **문제별 역할 분류**

    - Quantitative Output (정량적 출력) : 예측할 때는 **회귀(regression)** 사용
 
    - Qualitative Output (정성적 출력) : 예측할 때는 **분류(classification)** 사용
 
    - 어떤 방법들은 정량적 입력에 가장 적합하게 정의되고, 어떤 방법들은 정성적 입력에 더 적합하며, 어떤 방법들은 두 경우 모두에 사용할 수 있다
 
        - 정량적 : 선형 회귀
     
        - 정성적 : 나이브 베이즈
     
        - 둘 다 : 결정 트리

<br/>

### Qualitative variables (정성적 출력)

- **Qualitative variables (정성적 출력)** : 값이 수치가 아니라 **범주(카테고리)** 를 나타내는 변수

    - 보통 숫자 코드로 표현함
 
        - 보통 하나의 이진수(bit)로 0/1 또는 -1/1로 표현
     
        - 이런 숫자 코드를 타겟(target)이라고 부르기도 한다
 
    - 범주가 두 개만 있을 때
 
        - ex: 남=0, 여=1
     
    - 만약 범주가 두 개 이상일 경우 : **더미 변수(dummy variable)** 사용, 즉 **원-핫 인코딩(one-hot encoding)** 사용
 
        - K개의 범주를 가진 질적 변수는 K개의 이진 변수(비트)로 표현되며, 한 번에 하나만 ‘켜져(on)’ 있다
     
        - ex: {Red, Blue, Green} → Red=(1,0,0), Blue=(0,1,0), Green=(0,0,1)


- **우리의 목표**

    - 입력 벡터 X가 주어졌을 때, **출력 Y를 잘 예측하는 것**이 목표이며, 예측값은 Ŷ(“y-hat”)으로 표시
 
        - Y는 실제값, Ŷ는 모델의 예측값 

<br/>

### Statistical Decision Theory (통계적 의사결정 이론) : 정량적 출력 용어 정리

- 정량적 출력을 수학적으로 다뤄보자

    - X ∈ ℝᵖ : X는 p차원 실수값 (random input vector)

    - Y ∈ ℝ : Y는 실수값(random output variable)

    - Pr(X, Y) : X와 Y의 결합 분포(joint distribution)

    - f(X) : 입력 X가 주어졌을 때 Y를 예측하는 함수
 
        - **머신러닝의 목표**는 Y를 잘 표현할 수 있는 f(x)를 찾는 것 
     
    - L(Y, f(X)) : 손실함수
 
        - 가장 흔한 손실함수 : L(Y, f(X)) = (Y – f(X))² (제곱 오차(squared error loss))

<br/>

### 기대 제곱 예측 오차(Expected squared prediction error)

- **기대 제곱 예측 오차(Expected squared prediction error)**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/EPE.png)
 
    - 기대 제곱 예측 오차(EPE)는 (Y – f(X))²의 **기댓값**
 
        - **기대값(expectation)** : 어떤 과정을 무한히 반복했을 때 얻게 되는 평균 결과
     
        - 기대값은 E로 표기하고 **확률 분포**에 의해 정해지는 **가중 평균**이다 
      
    - 이것은 f를 선택하는 기준으로 사용
 
    - 여기서 우리는 입력(X)과 출력(Y) 모두에서 확률 변수와 불확실성을 다룬다
 
        - 입력과 출력이 고정된 값이 아니라, 확률적으로 변할 수 있으므로 전체 분포에 걸친 평균적 오차를 계산해야 한다

    - 단순히 훈련 데이터에서 오차를 최소화하는 게 아니라, 전체 분포에서 **평균적으로** 오차가 최소가 되는 함수 f를 찾는 게 목표












































