### Validation Set Approach (검증 세트 접근법)

- 데이터가 충분히 많을 경우, 가장 좋은 방법은 데이터를 무작위로 세 부분(훈련 세트, 검증 세트, 테스트 세트)으로 나누는 것이다.

    - **훈련 세트 (training set)** : 모델을 학습시키는 데 사용
 
    - **검증 세트 (validation set)** : 모델 선택을 위해 예측 오차를 추정하는 데 사용
 
    - **테스트 세트 (test set)** : 최종적으로 선택된 모델의 일반화 오차를 평가하는 데 사용

<br/>

- 세 부분에 얼마나 데이터를 배분할지는 일반적인 규칙을 주기 어렵다. 이는 데이터의 **신호-대-잡음 비율**과 훈련 샘플 크기에 달려 있기 때문이다

    - 데이터가 복잡하거나 잡음이 많으면 검증/테스트에 더 많이 할당할 수도 있고, 단순하면 적게 할 수도 있다. 즉 상황 따라 다르다
 
    - 일반적인 분할 예시는 훈련 50%, 검증 25%, 테스트 25%이다

<br/>

### k-Fold Cross-Validation

- 데이터를 k개의 동일한 크기 부분(폴드)로 나눈다. 보통 k=5 또는 k=10을 사용한다

    - k 중에서 하나씩 돌아가며 i번째를 테스트 세트로 사용하고 나머지를 훈련 세트로 사용한다
 
        - 여기서 훈련 세트와 검증 세트의 경우의 수를 다양하게 한 것이고, 테스트 세트는 이후 별도로 사용한다.
     
        - 따라서 각 분리 과정은 훈련 세트와 검증 세트만 분리하는 것이다  
 
    - 이렇게 얻은 k개의 테스트 오차를 평균낸다
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-2장k-flod테스트오차평균.png)
     
        - k개의 테스트 오차(MSE)를 평균내어 최종 점수로 삼는다

<br/>

- **k-fold 장점**

    - 모든 데이터를 학습과 검증에 **모두 활용**
 
        - 데이터 낭비가 없고, 작은 데이터셋에서도 효율적

    - 한 번만 나눠서 검증하는 방법보다 **더 안정적인 추정치**를 준다
 
    - 데이터 분할에 대한 의존성을 줄인다
 
        - 특정 Train/Test 분할에 따라 결과가 크게 달라지는 문제를 완화한다 

<br/>

### Leave-One-Out Cross-Validation (LOOCV)

- **데이터를 하나씩 빼서(test)**, **나머지로 학습(train)** 하는 교차검증 방식

    - 검증 세트(validation set)를 두지 않고, 각 데이터가 번갈아 가며 테스트 역할을 함

    - **작은 데이터셋에 효과적**이고 적합하다
 
        - 데이터가 너무 적으니까 Train/Validation/Test로 잘라버리면 학습할 데이터가 **부족해짐**
     
        - 그래서 Validation 세트를 따로 두지 않고 → 각 데이터가 한 번씩 Test 역할을 하도록 함
     
        - 즉, n개의 데이터 중 n-1개는 Train, 1개는 Test로 쓰고, 이걸 n번 반복해서 평균낸다
 
    - 특수한 경우: k = n
 
        - n-1개의 데이터로 학습하고, 남은 1개로 테스트한다
     
        - 이 과정을 모든 n개의 데이터에 대해 반복

<br/>































































































