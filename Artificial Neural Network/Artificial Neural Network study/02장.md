### From Biology to Artificial Intelligence

- 생물학적 뉴런의 구성 요소
  
    - 수상돌기(Dendrite): 입력을 받는 부분 (안테나처럼 신호를 받음)
 
    - 세포체(Cell body, Soma): 상돌기로 받은 신호들을 종합하고 계산하는 부분. CPU처럼 중앙 처리기 역할
 
    - 축삭(Axon) : 출력 신호를 전달하는 부분
 
    - 시냅스(Synapse): 뉴런과 뉴런 사이의 연결 지점. 신호가 실제로 전달되는 접점

<br/>

- **핵심 원리**: 입력이 **임계값을 넘으면** 뉴런은 발화(fire)한다 (반응한다)

- 뉴런 발화 과정

    - 많은 뉴런으로부터 신호를 받는다
 
    - 이 신호들을 합친다
 
    - 합이 임계값을 넘으면 발화한다
 
    - 전부 아니면 전무(All-or-nothing) 반응
     
        - 뉴런은 조금만 발화하거나 약하게 발화하는 게 없음. 기준치를 넘으면 100% 반응하고, 안 넘으면 0% 반응함

<br/>

- 뉴런은 수상돌기로 입력 신호를 받고 → 세포체에서 처리하고 → 축삭을 통해 출력 신호를 전달하며 → 시냅스에서 다른 뉴런과 연결된다

![System Resources](../../images/Artificial%20Neural%20Network%20images/뉴런구조.png)

<br/>

### Neurons (뉴런)

- **뉴런** : 뇌와 신경계 속 작은 처리 단위

    - 인간의 뇌에는 약 860억 개의 뉴런이 존재
 
        - 뉴런은 엄청나게 많아, 뇌가 고도의 정보처리를 할 수 있음
     
    - 뉴런은 가느다란 케이블을 통해 전기적, 화학적 신호로 소통함 

<br/>

- **감각 뉴런 (Sensory Perception)** : 신호를 뇌와 척수로 보낸다

    - 뉴런이 감각 정보를 처리하고 반응하도록 도와준다
 
        - ex: 뜨거운 것을 만졌을 때 바로 손을 떼는 현상  

<br/>

- 뉴런은 시냅스라 불리는 작은 틈을 통해 소통한다

    - 뉴런과 뉴런은 직접 붙어 있지 않고, 사이에 있는 시냅스을 통해 화학물질로 신호를 주고받음 

- 자주 소통할수록 시냅스가 강화되어, 학습과 기억에 도움을 준다

    - ex: 영어 단어를 자꾸 외우면 기억에 오래 남음 

<br/>

- **신경가소성 (Neuroplasticity)** : 경험을 통해 뇌가 변화할 수 있는 능력

    - 뇌는 고정된 것이 아니라, 새로운 경험을 하면 뉴런 연결이 바뀌고 뇌 구조도 달라질 수 있다.

        -  ex : 악기를 배우면 뇌의 관련 영역이 발달

<br/>

### Biological Neurons 과 Artificial Neurons 차이점 

- **Biological Neurons (생물학적 뉴런)**

    - 각각 약 1만 개의 연결을 가짐
 
    - 복잡한 시간적 역학(변화)
 
        - 신호가 시간에 따라 달라지고, 단순히 ‘켜짐/꺼짐’이 아니라 연속적인 변화가 있음 

    - 화학적, 전기적 신호를 사용해서 소통
 
    - 지속적으로 적응

<br/>

- **Artificial Neurons (Perceptrons, 인공 뉴런)**

    - 원하는 만큼 입력을 가질 수 있음
 
    - 단순한 수학 연산만 수행
 
        - 가중치 곱하기, 더하기, 임계값 비교 같은 간단한 연산
     
    - 디지털 신호 사용
 
        - 0 또는 1 같은 이산적인 신호로 계산

    - 학습 후에는 고정됨

<br/>

- Perceptrons (인공 뉴런) 예시 : 밖에 나가야 할까?

    - input data

        - x₁ = Is it sunny? (1=yes, 0=no)

        - x₂ = Is it warm? (1=yes, 0=no)

        - x₃ = Is it raining? (1=yes, 0=no)
     
    - 뉴런은 이런 가중치를 학습할 수 있다
 
        - w₁ = +2 (sunny is good) → w₁=+2 (햇볕은 좋음)

        - w₂ = +1 (warm is nice) → w₂=+1 (따뜻한 건 좋음)

        - w₃ = -3 (rain is bad) → w₃=-3 (비는 나쁨)
     
    - **의사결정: (2×햇볕 + 1×따뜻함 - 3×비 - 1) > 0 이면, 나간다**


- 즉, 입력 → 가중치 적용 → 합산 → 임계값 비교 → 출력 결정을 수행

<br/>

### 생물학적 뉴런 ->수학적 퍼셉트론 모델 변 과정 

- 생물학적 뉴런을 바탕으로한 변환 과정 

    - 수상돌기 (Dendrite)가 신호를 받는다 → 입력값으로 표현 (x₁, x₂, …, xₙ)

    - 시냅스 (Synaptic)의 강도 → 가중치 (w₁, w₂, …, wₙ)

    - 세포체 (soma)에서 통합 → 가중합 계산 Σ wᵢxᵢ

    - 발화 임계값 → 편향(b)

    - 발화/비발화 → 활성화 함수

- 퍼셉트론 식: (가중합 + 편향) > 0 이면 출력=1, 그렇지 않으면 0

<br/>

![System Resources](../../images/Artificial%20Neural%20Network%20images/퍼셉트론구조.png)

<br/>

### 활성화 함수(Activation Function) 

- 활성화 함수(Activation Function) : 뉴런이 계산한 가중합(입력 × 가중치 + 편향)을 받아, 이를 출력값으로 변환하여 뉴런의 발화 여부나 강도를 결정하는 함수

![System Resources](../../images/Artificial%20Neural%20Network%20images/활성화함수.png)

- 활성화함수 공식 
  
![System Resources](../../images/Artificial%20Neural%20Network%20images/활성화함수공식.png)

 - 활성화함수 공식 예시

    - 입력 특징

        - x1 = 햇볕이 있음 (1/0)

        - x2 = 따뜻함 (1/0)

        - x3 = 비가 옴 (1/0)

    - 가중치

        - w1 = +2 (햇볕은 좋음)

        - w2 = +1 (따뜻한 건 좋음)

        - w3 = -3 (비는 나쁨)

    - 편향

        - b = -1 (조금 귀찮음)
     
    - 만약 날씨가 맑고 따뜻하고 비 안 온다면 (x=[1,1,0])

        - w⋅x+b=(2)(1)+(1)(1)+(−3)(0)−1=2+1+0−1=2>0 처럼 내적을 사용 
     
        - 출력 : 밖에 나간다(1)
    

 ### Linear Decision Boundaries (선형 결정 경계)

 - **Linear Decision Boundaries**

 - 머신러닝에서 분류를 할 때, 데이터를 구분하는 경계

     - 1차원 : 점(point)
  
     - 2차원 : 선(line)
  
     - 3차원 : 면(plane)
  
     - 4차원 이상 : 초평면(hyperplane) -> 직접 볼 수 없음 

<br/>

- 선형 결정 경계 공식
  
![System Resources](../../images/Artificial%20Neural%20Network%20images/선형결정경계공식.png)

- 위 공식을 보면 wTx 는 **내적**을 의미한다

    - wTx + b = w[0]x[0] + w[1]x[1] + ... + w[m-1]x[m-1] + b
 
    - 즉, 내적은 각 차원의 가중치 x 특징값을 모두 더한 값
 
        - b를 오른쪽으로 이항시킴으로서 기준을 0으로 일반화 가능 
     
        - 이 식은 n차원에서도 동일하게 적용 가능함

<br/>

- **특징 계수(feature coefficient)**

    - 벡터 w는 각 특징(입력값 x)에 곱해지는 가중치들을 모아둔 것
 
        - 이 가중치 하나하나를 **계수(coefficient)** 라고 함  
  
    - ex: 스팸 이메일을 분류한다고 하고, 네 번째 특징 x[4]이 이메일에 포함된 철자 오류 개수를 나타낸다고 하자
 
        - 만약 이 특징의 계수 w[4]가 양수라면, 철자 오류 개수가 많을수록 스팸으로 분류 가능성이 커짐
     
        - 즉, 가중치 벡터 w의 각 원소는 해당 특징이 결과에 미치는 **영향력(계수)** 을 의미

<br/>

- **bias term b (편향 b)**

    - 편향 b는 **입력 특징(feature)에 의존하지 않는다**
 
        - 즉, wTx는 입력 특징값 x에 따라 변하지만, **b는 항상 고정된 상수**
     
            - 데이터와 무관하게 **결정 경계를 평행 이동**시키는 역할
         
            - 따라서 전체 예측 결과를 더 긍정적(+1 쪽) 또는 부정적(-1 쪽)으로 이동시킬 수 있음
            - 만약 b가 큰 음수라면, 모델은 전체적으로 음수(-1) 예측을 하도록 치우치게 됨

    <br/>


    - 편향 항을 포함하는 것은 **필수적**이다
 
    - 선형 결정 경계로 완벽하게 분리 가능한 데이터셋이 있더라도, 바이어스 항이 없으면 그렇게 하는 것이 **불가능**할 수 있음
 
        - ex: b=0이면, 결정 경계는 무조건 원점(0,0)을 지나야 하지만 실제 데이터는 원점을 중심으로 대칭적으로 분리되지 않을 수 있음
     
        - 따라서 b가 있어야 경계를 옮겨서 데이터를 **제대로 분리가 가능**함









































