- 04-1장의 핵심

    - 훈련 성능과 테스트 성능의 차이 파악
 
    - 훈련 데이터를 완벽히 맞추는 모델이 왜 새로운 데이터에서는 종종 실패하는지
 
    - 바이어스-분산 절충과 그 의미

<br/>

### 성능 평가(Performance Assessment) 가 필요한 이유 

- **The Fundamental Problem (근본적인 문제)**

    - 우리는 새로운, 본 적 없는 데이터를 예측하기 위해 모델을 만들지만 모델 개발 단계에서는 학습 데이터밖에 쓸 수 없다
 
        - 즉, 모델이 처음 보는 데이터에 대해 잘 작동하는지 알 수 없음 

        - 예시 : 훈련 데이터를 완벽히 외운 모델(정확도 100%) 일지라도 새로운 데이터에서는 성능이 50% 가까 떨어질 수 있다 (overfitting)

            - 이 차이는 올바른 성능 평가의 필요성을 보여준다
 
<br/>

- 통계적 학습 방법의 성능을 평가하기 위해서는, **모델의 예측이 실제 관측된 데이터와 얼마나 잘 맞는지**를 측정할 방법이 필요하다

    - 따라서, 주어진 관측치에 대해 예측된 응답값이 실제 응답값과 얼마나 가까운지를 **수치**로 나타낼 필요가 있다 

<br/>

### Training Error

- **mean squared error (MSE,평균 제곱 오차)**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장MSE공식자료.png)
 
    - MSE는 모든 훈련 데이터에서 **(실제값 - 예측값)의 제곱을 평균**낸 것
 
    - n : 훈련 데이터 개수

    - yi : i번째 실제 값

    - f(xi) : i번째 입력에 대한 모델의 예측값

<br/>

- **MSE 문제점** : Training Error(훈련 오류)는 우리가 이미 본 데이터에 대해 얼마나 잘 맞췄는지만 측정한다. 하지만 우리가 진짜로 중요한 것은 보지 않은 **새로운 데이터를 예측하는 것**이다

    - 즉, 훈련데이터만 예측이 가능하지만, 모델이 일반화에 성공했는지는 알 수 없다 

<br/>

### Test Error 

- 우리가 관심 있는 것은, 모델을 아직 보지 못한 테스트 데이터에 적용했을 때 얻는 예측의 정확도이다

    - 즉, **본질은 Test Error를 줄이는 것이다**

<br/>

- **Test Error 공식**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장MSE공식자료.png)
 
    - 실제값과 예측값의 차이 제곱의 **기댓값**
 
    - X0와 Y0는 훈련에 사용되지 않은 새로운 관측값이고 무작위로 바뀔 수 있는 변수다 

<br/>

- **Traing Error vs Test Error 해석 관점**

    - **Train Error**
    
        - 훈련 데이터셋 (xi,yi)는 **이미 고정된 표본(sample)** 임
 
        - 하지만, 기댓값은 **확률 변수(random variable)** 에 대해 정의된다.
     
            - 따라서 기댓값은 X,Y가 **확률 변수**일 때, 즉 새로운 데이터가 무작위로 들어오는 경우의 예측 성능을 평가할 때 사용한다
         
            - 반대로 **훈련 데이터는 이미 모두 주어진 값**이므로, 그 위에서는 단순히 평균 오차를 계산하면 충분하다

    - **Test Error**
 
        - 새로운 데이터 (X0,Y0)는 모집단 분포에서 무작위로 추출되는 확률 변수이므로, 개별 관측값만으로는 알 수 없다.

        - 따라서 **분포 전체에 대해 평균적인 오차(기댓값)** 를 기준으로 성능을 평가

<br/>

- **핵심 정리** : 우리는 훈련 MSE가 가장 낮은 모델이 아니라, **테스트 MSE가 가장 낮은 모델**을 선택해야 한다

<br/>

### Classification Performance Metrics (분류 성능 지표)

- **Training Error Rate**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분류성능지표공식자료.png)
 
    - 훈련 오류율 : n개의 훈련 데이터에서 **실제 정답 y_i와 예측값 y_i_hat 다른 비율**
 
    - 여기서 I(⋅)는 지시 함수 → 조건이 참이면 1, 거짓이면 0.

<br/>

- **Test error rate**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분류성능지표테스트에러공식자료1.png)
 
    - 해당 공식은 유한한 테스트 샘플에서 구한 표본 **평균 오류율**이고 아래 공식은 모집단 전체 분포에서 정의된 **이론적 기대 오류율**
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분류성능지표테스트에러공식자료2.png)

<br/>

### 모델 선택의 어려움

- **이상적인 상황** : **테스트 데이터**가 존재할 때

    - (1) : 단순히 각 후보 모델을 테스트 데이터로 평가
 
    - (2) : 테스트 MSE(또는 오류율)가 가장 낮은 모델을 선택
 
    - (3) : 이것은 일반화 성능에 대한 직접적인 근거를 줌
 
<br/>

- **현실적인 상황**: 모델 선택 과정에서 테스트 데이터는 없다

    - 유혹적이지만 **잘못된 접근** : 훈련 MSE가 가장 낮은 모델을 고르자
 
        - -> **실패한다** : 훈련 MSE는 매우 작을 수 있지만, 테스트 MSE는 훨씬 커질 때가 많다

<br/>

### Model flexibility and fits (모델의 유연성과 적합)

- ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장모델유연성자료1.png)

    - 데이터 점(동그라미)이 주어져 있고
 
    - 검은색 곡선 : 데이터가 실제로 따라야 하는 “진짜 패턴”

    - 세 가지 모델이 데이터를 학습한 결과 곡선으로 나타남

        - 주황색 직선: 단순한 모델 (자유도 낮음, underfitting 경향)

        - 파란색 곡선: 적당히 유연한 모델 (적절한 복잡도, 좋은 일반화)

        - 초록색 곡선: 지나치게 복잡한 모델 (자유도 높음, overfitting 경향)

    - 위 그래프로 모델의 복잡도를 표현해보자
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장모델복잡도그래프자료1.png)
     
        - 가로축: 모델의 복잡도(flexibility, df)

        - 세로축: 평균 제곱 오차(MSE)

        - 곡선 두 개:

            - 회색: 훈련 MSE → 복잡도가 커질수록 계속 줄어든다

            - 빨간색: 테스트 MSE → 처음엔 줄다가, 일정 수준 이상 복잡해지면 다시 커진다 (과적합)
         
        - 주황색, 파란색, 초록색 네모 칸은 해당 모델의 복잡도에서의 MSE 위치이다 
     
            - 주황색 직선 모델: 단순 → 테스트 MSE가 높음 (과소적합)

            - 파란색 곡선 모델: 적당한 유연성 → 테스트 MSE가 가장 낮음 (최적)

            - 초록색 복잡한 모델: 과하게 유연 → 테스트 MSE가 다시 커짐 (과적합)     

<br/>

- **위 그래프 정리**
  
    - **선형회귀보다 곡선이 더 유연성이 뛰어남** -> 복잡한 모델을 더 잘 표현할 수 있음
 
    - 모델의 **유연성이 증가**할수록, 곡선이 관측된 데이터(점)와 **더 가깝게** 맞춰진다
 
    - 초록색 곡선은 가장 유연하여 데이터를 매우 잘 맞춘다. 하지만 실제 함수 f(검은 곡선)와는 잘 맞지 않는데, 그 이유는 너무 요동(진동)이 심하기 때문 -> **과적합 상황**
 
    - 유연성 수준을 조절함으로써, 이 데이터에 대해 여러 가지 다른 적합 결과를 얻을 수 있다
 
        - 즉 아래와 같이 실제 함수가 선형에 가깝다면, 복잡한 모델을 사용할 필요 없이 단순한 선형 회귀 모델이 더 도움이 된다
     
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장선형회귀모델이더적합한경우그래프예시.png)

<br/>

### Bias & Variance

- 예측 오류를 바이어스, 분산으로 나눠서 이해해보자

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개.png)

<br/>


- **공식 증명 과정**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개1.png)
 
    - 위 기댓값 내부 전개 과정은 아래와 같다
 
    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개2.png)
 
    - 위 공식에서 2E[ϵf(x0)-f_hat(x0)]가 사라지는 이유는 잡음 ϵ의 평균은 0이고 E[ϵ]=0 이므로 해당 항 내부가 0이 되어 사라지는 것이다
 
    - 또한 분산 공식을 적용하면 아래와 같다
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개3.png)
     
        - ε의 평균이 0이라는 것은 -2,-1,1,2 와 같이 다 더해서 평균적으로 0이라는 것이고 ε 제곱은 양수이므로 헷갈리지 않게 조심해야한다 
     
        - 따라서 잡음 기호인 잡음 ε에 대한 σ 제곱은 Var(ε)와 동일하다 

    - 현재까지 완료된 공식을 보면 아래와 같다
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개4.png)
     
        - 위 공식에서 앞에 제곱으로 이루어진 기댓값을 전개하기 위해 아래 공식을 사용하자
     
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개5.png)
     
        - 여기서 Z = f_hat(x0), c = f(x0)로 두면 아래 공식이 성립한다
     
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개6.png)

    - 따라서 최종적으로 아래 공식이 성립한다
 
    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값최종공식전개.png)





































































