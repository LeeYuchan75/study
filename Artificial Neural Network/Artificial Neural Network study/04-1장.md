- 04-1장의 핵심

    - 훈련 성능과 테스트 성능의 차이 파악
 
    - 훈련 데이터를 완벽히 맞추는 모델이 왜 새로운 데이터에서는 종종 실패하는지
 
    - 바이어스-분산 절충과 그 의미

<br/>

### 성능 평가(Performance Assessment) 가 필요한 이유 

- **The Fundamental Problem (근본적인 문제)**

    - 우리는 새로운, 본 적 없는 데이터를 예측하기 위해 모델을 만들지만 모델 개발 단계에서는 학습 데이터밖에 쓸 수 없다
 
        - 즉, 모델이 처음 보는 데이터에 대해 잘 작동하는지 알 수 없음 

        - 예시 : 훈련 데이터를 완벽히 외운 모델(정확도 100%) 일지라도 새로운 데이터에서는 성능이 50% 가까 떨어질 수 있다 (overfitting)

            - 이 차이는 올바른 성능 평가의 필요성을 보여준다
 
<br/>

- 통계적 학습 방법의 성능을 평가하기 위해서는, **모델의 예측이 실제 관측된 데이터와 얼마나 잘 맞는지**를 측정할 방법이 필요하다

    - 따라서, 주어진 관측치에 대해 예측된 응답값이 실제 응답값과 얼마나 가까운지를 **수치**로 나타낼 필요가 있다 

<br/>

### Training Error

- **mean squared error (MSE,평균 제곱 오차)**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장MSE공식자료.png)
 
    - MSE는 모든 훈련 데이터에서 **(실제값 - 예측값)의 제곱을 평균**낸 것
 
    - n : 훈련 데이터 개수

    - yi : i번째 실제 값

    - f(xi) : i번째 입력에 대한 모델의 예측값

<br/>

- **MSE 문제점** : Training Error(훈련 오류)는 우리가 이미 본 데이터에 대해 얼마나 잘 맞췄는지만 측정한다. 하지만 우리가 진짜로 중요한 것은 보지 않은 **새로운 데이터를 예측하는 것**이다

    - 즉, 훈련데이터만 예측이 가능하지만, 모델이 일반화에 성공했는지는 알 수 없다 

<br/>

### Test Error 

- 우리가 관심 있는 것은, 모델을 아직 보지 못한 테스트 데이터에 적용했을 때 얻는 예측의 정확도이다

    - 즉, **본질은 Test Error를 줄이는 것이다**

<br/>

- **Test Error 공식**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장MSE공식자료.png)
 
    - 실제값과 예측값의 차이 제곱의 **기댓값**
 
    - X0와 Y0는 훈련에 사용되지 않은 새로운 관측값이고 무작위로 바뀔 수 있는 변수다 

<br/>

- **Traing Error vs Test Error 해석 관점**

    - **Train Error**
    
        - 훈련 데이터셋 (xi,yi)는 **이미 고정된 표본(sample)** 임
 
        - 하지만, 기댓값은 **확률 변수(random variable)** 에 대해 정의된다.
     
            - 따라서 기댓값은 X,Y가 **확률 변수**일 때, 즉 새로운 데이터가 무작위로 들어오는 경우의 예측 성능을 평가할 때 사용한다
         
            - 반대로 **훈련 데이터는 이미 모두 주어진 값**이므로, 그 위에서는 단순히 평균 오차를 계산하면 충분하다

    - **Test Error**
 
        - 새로운 데이터 (X0,Y0)는 모집단 분포에서 무작위로 추출되는 확률 변수이므로, 개별 관측값만으로는 알 수 없다.

        - 따라서 **분포 전체에 대해 평균적인 오차(기댓값)** 를 기준으로 성능을 평가

<br/>

- **핵심 정리** : 우리는 훈련 MSE가 가장 낮은 모델이 아니라, **테스트 MSE가 가장 낮은 모델**을 선택해야 한다






