- 04-1장의 핵심

    - 훈련 성능과 테스트 성능의 차이 파악
 
    - 훈련 데이터를 완벽히 맞추는 모델이 왜 새로운 데이터에서는 종종 실패하는지
 
    - 바이어스-분산 절충과 그 의미

<br/>

### 성능 평가(Performance Assessment) 가 필요한 이유 

- **The Fundamental Problem (근본적인 문제)**

    - 우리는 새로운, 본 적 없는 데이터를 예측하기 위해 모델을 만들지만 모델 개발 단계에서는 학습 데이터밖에 쓸 수 없다
 
        - 즉, 모델이 처음 보는 데이터에 대해 잘 작동하는지 알 수 없음 

        - 예시 : 훈련 데이터를 완벽히 외운 모델(정확도 100%) 일지라도 새로운 데이터에서는 성능이 50% 가까 떨어질 수 있다 (overfitting)

            - 이 차이는 올바른 성능 평가의 필요성을 보여준다
 
<br/>

- 통계적 학습 방법의 성능을 평가하기 위해서는, **모델의 예측이 실제 관측된 데이터와 얼마나 잘 맞는지**를 측정할 방법이 필요하다

    - 따라서, 주어진 관측치에 대해 예측된 응답값이 실제 응답값과 얼마나 가까운지를 **수치**로 나타낼 필요가 있다 

<br/>

### Training Error

- **mean squared error (MSE,평균 제곱 오차)**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장MSE공식자료.png)
 
    - MSE는 모든 훈련 데이터에서 **(실제값 - 예측값)의 제곱을 평균**낸 것
 
    - n : 훈련 데이터 개수

    - yi : i번째 실제 값

    - f(xi) : i번째 입력에 대한 모델의 예측값

<br/>

- **MSE 문제점** : Training Error(훈련 오류)는 우리가 이미 본 데이터에 대해 얼마나 잘 맞췄는지만 측정한다. 하지만 우리가 진짜로 중요한 것은 보지 않은 **새로운 데이터를 예측하는 것**이다

    - 즉, 훈련데이터만 예측이 가능하지만, 모델이 일반화에 성공했는지는 알 수 없다 

<br/>

### Test Error 

- 우리가 관심 있는 것은, 모델을 아직 보지 못한 테스트 데이터에 적용했을 때 얻는 예측의 정확도이다

    - 즉, **본질은 Test Error를 줄이는 것이다**

<br/>

- **Test Error 공식**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장MSE공식자료.png)
 
    - 실제값과 예측값의 차이 제곱의 **기댓값**
 
    - X0와 Y0는 훈련에 사용되지 않은 새로운 관측값이고 무작위로 바뀔 수 있는 변수다 

<br/>

- **Traing Error vs Test Error 해석 관점**

    - **Train Error**
    
        - 훈련 데이터셋 (xi,yi)는 **이미 고정된 표본(sample)** 임
 
        - 하지만, 기댓값은 **확률 변수(random variable)** 에 대해 정의된다.
     
            - 따라서 기댓값은 X,Y가 **확률 변수**일 때, 즉 새로운 데이터가 무작위로 들어오는 경우의 예측 성능을 평가할 때 사용한다
         
            - 반대로 **훈련 데이터는 이미 모두 주어진 값**이므로, 그 위에서는 단순히 평균 오차를 계산하면 충분하다

    - **Test Error**
 
        - 새로운 데이터 (X0,Y0)는 모집단 분포에서 무작위로 추출되는 확률 변수이므로, 개별 관측값만으로는 알 수 없다.

        - 따라서 **분포 전체에 대해 평균적인 오차(기댓값)** 를 기준으로 성능을 평가

<br/>

- **핵심 정리** : 우리는 훈련 MSE가 가장 낮은 모델이 아니라, **테스트 MSE가 가장 낮은 모델**을 선택해야 한다

<br/>

### Classification Performance Metrics (분류 성능 지표)

- **Training Error Rate**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분류성능지표공식자료.png)
 
    - 훈련 오류율 : n개의 훈련 데이터에서 **실제 정답 y_i와 예측값 y_i_hat 다른 비율**
 
    - 여기서 I(⋅)는 지시 함수 → 조건이 참이면 1, 거짓이면 0.

<br/>

- **Test error rate**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분류성능지표테스트에러공식자료1.png)
 
    - 해당 공식은 유한한 테스트 샘플에서 구한 표본 **평균 오류율**이고 아래 공식은 모집단 전체 분포에서 정의된 **이론적 기대 오류율**
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분류성능지표테스트에러공식자료2.png)

<br/>

### 모델 선택의 어려움

- **이상적인 상황** : **테스트 데이터**가 존재할 때

    - (1) : 단순히 각 후보 모델을 테스트 데이터로 평가
 
    - (2) : 테스트 MSE(또는 오류율)가 가장 낮은 모델을 선택
 
    - (3) : 이것은 일반화 성능에 대한 직접적인 근거를 줌
 
<br/>

- **현실적인 상황**: 모델 선택 과정에서 테스트 데이터는 없다

    - 유혹적이지만 **잘못된 접근** : 훈련 MSE가 가장 낮은 모델을 고르자
 
        - -> **실패한다** : 훈련 MSE는 매우 작을 수 있지만, 테스트 MSE는 훨씬 커질 때가 많다

<br/>

### Model flexibility and fits (모델의 유연성과 적합)

- ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장모델유연성자료1.png)

    - 데이터 점(동그라미)이 주어져 있고
 
    - 검은색 곡선 : 데이터가 실제로 따라야 하는 “진짜 패턴”

    - 세 가지 모델이 데이터를 학습한 결과 곡선으로 나타남

        - 주황색 직선: 단순한 모델 (자유도 낮음, underfitting 경향)

        - 파란색 곡선: 적당히 유연한 모델 (적절한 복잡도, 좋은 일반화)

        - 초록색 곡선: 지나치게 복잡한 모델 (자유도 높음, overfitting 경향)

    - 위 그래프로 모델의 복잡도를 표현해보자
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장모델복잡도그래프자료1.png)
     
        - 가로축: 모델의 복잡도(flexibility, df)

        - 세로축: 평균 제곱 오차(MSE)

        - 곡선 두 개:

            - 회색: 훈련 MSE → 복잡도가 커질수록 계속 줄어든다

            - 빨간색: 테스트 MSE → 처음엔 줄다가, 일정 수준 이상 복잡해지면 다시 커진다 (과적합)
         
        - 주황색, 파란색, 초록색 네모 칸은 해당 모델의 복잡도에서의 MSE 위치이다 
     
            - 주황색 직선 모델: 단순 → 테스트 MSE가 높음 (과소적합)

            - 파란색 곡선 모델: 적당한 유연성 → 테스트 MSE가 가장 낮음 (최적)

            - 초록색 복잡한 모델: 과하게 유연 → 테스트 MSE가 다시 커짐 (과적합)     

<br/>

- **위 그래프 정리**
  
    - **선형회귀보다 곡선이 더 유연성이 뛰어남** -> 복잡한 모델을 더 잘 표현할 수 있음
 
    - 모델의 **유연성이 증가**할수록, 곡선이 관측된 데이터(점)와 **더 가깝게** 맞춰진다
 
    - 초록색 곡선은 가장 유연하여 데이터를 매우 잘 맞춘다. 하지만 실제 함수 f(검은 곡선)와는 잘 맞지 않는데, 그 이유는 너무 요동(진동)이 심하기 때문 -> **과적합 상황**
 
    - 유연성 수준을 조절함으로써, 이 데이터에 대해 여러 가지 다른 적합 결과를 얻을 수 있다
 
        - 즉 아래와 같이 실제 함수가 선형에 가깝다면, 복잡한 모델을 사용할 필요 없이 단순한 선형 회귀 모델이 더 도움이 된다
     
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장선형회귀모델이더적합한경우그래프예시.png)

<br/>

### Bias & Variance

- 예측 오류를 바이어스, 분산으로 나눠서 이해해보자

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개.png)
 
    - 예측오차 = 줄일 수 없는 잡음 + 모델의 단순함(편향) + 데이터 민감성(분산)
 
        - 첫 번째 항은 **분산**으로, 모델이 학습 데이터에 따라 얼마나 흔들리는지를 나타낸다.
     
        - 두 번째 항은 **편향 제곱**으로, 예측값의 평균이 실제 함수 f(x0)와 얼마나 다른지를 의미한다
     
        - 마지막 항은 **잡음**으로, f(x0) 주변의 데이터의 자연스러운 분산이며, σε² = 0이 아닌 한 피할 수 없다
     
<br/>


- **공식 증명 과정**

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개1.png)
 
    - 위 기댓값 내부 전개 과정은 아래와 같다
 
    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개2.png)
 
    - 위 공식에서 2E[ϵf(x0)-f_hat(x0)]가 사라지는 이유는 우선 통계학/머신러닝 기본 가정은 잡음 ϵ는 입력 X와 및 모델 추정치 f_hat(x)와 독립이고, ϵ의 평균은 0이고, E[ϵ]=0 이므로 해당 항 내부가 0이 되어 사라지는 것이다
 
    - 또한 분산 공식을 적용하면 아래와 같다
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개3.png)
     
        - ε의 평균이 0이라는 것은 -2,-1,1,2 와 같이 다 더해서 평균적으로 0이라는 것이고 ε 제곱은 양수이므로 헷갈리지 않게 조심해야한다 
     
        - 따라서 잡음 기호인 잡음 ε에 대한 σ 제곱은 Var(ε)와 동일하다 

    - 현재까지 완료된 공식을 보면 아래와 같다
 
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개4.png)
     
        - 위 공식에서 앞에 제곱으로 이루어진 기댓값을 전개하기 위해 아래 공식을 사용하자
     
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개5.png)
     
        - 여기서 Z = f_hat(x0), c = f(x0)로 두면 아래 공식이 성립한다
     
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값공식전개6.png)

    - 따라서 최종적으로 아래 공식이 성립한다
 
    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장분산편향기댓값최종공식전개.png)

<br/>

### bias–variance dilemma (편향–분산 딜레마)

- **편향과 분산를 동시에 줄이려고** 할 때 생기는 **충돌**을 의미하며, 이는 학습된 알고리즘이 훈련 데이터 외의 **새로운 데이터에 일반화되는 것을 방해**한다

    - **Bias ↓** → 모델을 복잡하게 해야 함. 하지만 그러면 Variance ↑ (데이터에 따라 흔들림 심해짐).

    - **Variance ↓** → 모델을 단순하게 해야 함. 하지만 그러면 Bias ↑ (진짜 패턴을 놓침)
 
    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장편향분산딜레마이해를위한자료사진첨부.png)
 
        - **단순한 모델** : 편향이 크고, 분산은 작다 
     
            - **언더피팅 (Bias ↑, Variance ↓)** : 높은 편향은 알고리즘이 입력 특성과 출력 사이의 중요한 관계를 놓치게 만들 수 있다
         
                - 모델이 너무 단순하면 실제 패턴을 제대로 못 잡는다
             
                - ex: 직선 모델로 곡선 데이터를 설명하려고 하면 항상 엇나가게 된다
     
        - **복잡한 모델** : 편향은 작지만, 분산이 크다 
     
            - **오버피팅 (Bias ↓, Variance ↑)** : 높은 분산은 알고리즘이 훈련 데이터 속 무작위 잡음까지 모델링해버릴 때 발생할 수 있다
         
                - 모델이 너무 복잡하면 데이터의 우연한 잡음까지 외워버린다
             
                - 훈련 데이터는 잘 맞추지만 새로운 데이터에서는 크게 틀린다
     
        - 최적의 모델 복잡도는 **두 가지 오류(Bias와 Variance)의 균형**을 맞춘다
     
        - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장편향분산딜레마이해를위한그래프자료첨부.png)

<br/>

- **정리하면**

    - **편향** : 정답에서 빗나감의 정도
 
    - **분산** : 퍼져 있는 정도 

<br/>

### Bias–variance tradeoff 

- 아래 실험을 함께 보자 

- 80개의 관측치와 20개의 예측 변수들을, [0,1]^20 구간의 초입방체(hypercube)에 균일하게 분포시켰다

    - ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장편향분산트레이드오프그래프비교사진.png)
 
    - 시뮬레이션 예제에서 예상 **예측 오차**(주황색), **편향 제곱**(초록색), **분산**(파란색)을 나타낸 것이다
 
    - 또한, 크기가 p인 최적 부분집합 회귀(best subset regression)를 사용했다
 
        - 모든 변수를 다 쓰지 않고, p개만 골라서 모델을 만든다는 의
 
    - bias–variance 트레이드오프는 0–1 손실(분류)과 제곱오차 손실(회귀)에서 다르게 나타난다
 
        - **회귀(regression)**: 오차는 보통 제곱오차로 측정

        - **분류(classification)**: 오차는 0–1 손실(맞으면 0, 틀리면 1)로 측정

    <br/>
    
    - 위 실험을 통해 알 수 있는 점은
 
        - 회귀나 분류나 모두 편향과 분산이 같은 관계성을 가진다
     
            - 편향이 커지면 분산이 줄어들고, 편향이 작아지면, 분산이 늘어남  


        - 하지만 **예측 오차 (Prediction Error) 는손실 함수에 따라 달라진다**
     
            - 분류에서 쓰는 0–1 손실 함수는 맞으면 0, 틀리면 1로만 평가하기 때문에,
작은 확률 차이도 곧바로 정답/오답으로 바뀌어 **오차율이 크게 변한다**

            - 반면 회귀의 제곱오차 손실은 예측이 조금 틀려도 거리만큼 **점진적으로 오차가 증가하기 때문에** 곡선이 **완만**하다

<br/>

### 편향, 분산, mse 관계성 

- ![System Resources](../../images/Artificial%20Neural%20Network%20images/04-1장편향분산mse관계성을표현하는그래프사진자료.png)

    - 왼쪽 함수부터 실제 함수 𝑓가 각각 비선형, 선형에 가까움, 매우 비선형일 때의 편향(Bias²), 분산(Variance), 그리고 테스트 MSE의 관계 변화를 보여준다

    - 파란색 (Bias²)

        - 모델이 단순해서 “진짜 함수”와 평균적으로 얼마나 빗나가는지

        - 모델 복잡도가 커질수록 (flexibility ↑) → Bias²는 줄어듦

    - 주황색 (Variance)

        - 모델이 데이터셋마다 얼마나 흔들리는지 (일관성 문제)
          
        - 모델 복잡도가 커질수록 → Variance는 커짐

    - 빨간색 (Test MSE)

        - 실제 우리가 중요하게 보는 최종 예측 오차

        - Bias² + Variance + 노이즈가 합쳐진 값

        - 보통 U자형 곡선 → 중간 지점에서 최소값
     
<br/>

- 세 경우 모두, 모델의 유연성이 커질수록 분산은 증가하고 편향은 감소한다

    - 하지만 최적의 **테스트 MSE에 해당하는 유연성 수준**은 세 데이터셋마다 **크게 다르다**
        
        - 그 이유는 각 데이터셋에서 편향 제곱과 분산이 **변하는 속도**가 다르기 때문이다

    <br/>
    
    - 왼쪽 그림 (비선형 데이터) : 편향이 처음에 급격히 줄어들어서 예상 **테스트 MSE도 빠르게 감소**한다
 
    - 가운데 그림 (거의 선형 데이터) : 실제 함수 f가 **거의 선형**이기 때문에 **유연성이 커져도 편향 감소는 작다**. 그래서 테스트 MSE는 조금만 줄다가, 분산이 급격히 커지면서 **오히려 증가**한다
 
    - 오른쪽 그림 (매우 비선형 데이터) : 실제 함수 f가 매우 비선형이기 때문에, 유연성이 커질수록 편향이 극적으로 줄어든다
 
        - 또한, **유연성이 커져도 분산은 거의 증가하지 않는다**
     
        - 따라서 테스트 MSE는 모델이 복잡해질수록 크게 줄어들다가, **나중에 약간만 증가**한다
<br/>

- **정리하면**

    - **비선형 데이터** : 단순 모델은 성능이 나쁘지만, 조금만 복잡하게 하면 성능 급격히 좋아짐.

    - **거의 선형에 가까운 데이터** : 단순 모델도 충분히 잘 맞음. 너무 복잡하면 분산 때문에 오히려 나빠짐

    - **매우 비선형 데이터** : 복잡할수록 편향이 크게 줄고 분산 증가도 적어서 성능이 꾸준히 좋아짐






















































