### 1주차
- **Supervised learning (지도학습)** :정답 존재

    - MNIST 데이터셋 : 손글씨 예측
   
    - Object recognition (객체 인지) : 사진 속 물체 예측
   
    - Neural Machine Translation (신경망 기반 기계 번역) : 벡터를 이용해서 언어 변환 
   
    - Caption generation (캡션 생성) : 이미지에 맞는 문장 생성

<br/>

- **Unsupervised learning (비지도학습)** : 정답 없음

    - CycleGAN : 얼룩말 & 말 교체 가능 

<br/>

- **Reinforcement learning (강화학습)** : 보상 최대

    - DeepMind : 단일 신경망(single network)으로 Atari 2600 플레이

 <br/>
 
- **Statistical Learning (통계적 학습)**

    - 머신러닝 관점 : 맞고/틀리다(정답 예측)이 중요 ex: XGBOOST

    - 통계적 학습 관점 : **상관관계**를 찾고 설명하는 것 ex: linear regression, logistic regression
      
    - ex : 전립선암 위험 요인 찾기, 이메일 스팸 탐지, 유전자 기반 암 분류, 위성 이미지 픽셀 분류

<br/>

- **신경망(Neural Network, NN)**

    - 은닉층이 0개, 1개, 또는 여러 개여도 모두 신경망이라고 부름
 
    - 이미지 인식, 언어 번역, 음성 인식, 질병 진단, 로봇 제어

<br/>

- **심층신경망(Deep Neural Network, DNN)**

    - 은닉층이 2개 이상인 경우
 
<br/>

### 2 주차 

- **뉴런의 흐름**

    -  뉴런은 수상돌기로 입력 신호를 받고 → 세포체에서 처리하고 → 축삭을 통해 출력 신호를 전달하며 → 시냅스에서 다른 뉴런과 연결된다

<br/>

- **퍼셉트론의 핵심**

    - 틀린 점을 반대편으로 밀어서 **올바른 쪽**에 위치시키기 

    - **임계점** : (가중합 + 편향) > 0 이면 출력=1, 그렇지 않으면 0

    - **선형적**으로 구분된 경우만 분류 가능 (비선형적 ex: XOR, NP-hard 은 불가능)
 
        - 올바른 출력을 위한 가중치 업데이트를 반복
     
            - w := w + err × x 
     
        - 위 업데이트 후의 예측값이, 업데이트 전의 예측값보다 **항상 크거나 같다**

<br/>

- **Linear Decision Boundaries (선형 결정 경계)**

    - 데이터 공간을 양쪽으로 나누는 선/면/초평면 : **w⋅x+b = 0**

<br/>

- **Convergence Bounds**

    - 퍼셉트론은 무한히 학습하지 않고 **수렴**한다는 것을 보여줌 
